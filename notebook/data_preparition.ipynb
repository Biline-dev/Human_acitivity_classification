{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "LCfbGRR8UmmM",
        "outputId": "cd2a90d2-79ba-49cc-e464-6f13357ec7b9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "''"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import tensorflow as tf\n",
        "device_list = tf.test.gpu_device_name()\n",
        "device_list"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data preparition"
      ],
      "metadata": {
        "id": "hNK8I_URWlzV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data:\n",
        "\n",
        "* ├─1\n",
        "* │  …………\n",
        "* └─25\n",
        "\n",
        "  * ├─back\n",
        "  * ├─forward\n",
        "  * ├─halfsquat\n",
        "  * ├─still\n",
        "\n",
        "here 1-25 is the index of each participant.\n",
        "\n",
        "\n",
        "We attempted to automate the data processing workflow. We uploaded everything to the drive and created functions for extracting, segmenting, and concatenating the data. Further details about these functions will be provided in the following sections."
      ],
      "metadata": {
        "id": "iHx7U6eVW_77"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b46BqH38yR5y"
      },
      "outputs": [],
      "source": [
        "def ensure_dataframe(file_path):\n",
        "    \"\"\"\n",
        "    Read a CSV file if it exists; otherwise, return an empty DataFrame.\n",
        "    \"\"\"\n",
        "    if os.path.exists(file_path):\n",
        "        return pd.read_csv(file_path, index_col=0).T\n",
        "    else:\n",
        "        print(f\"File not found: {file_path}. Returning empty DataFrame.\")\n",
        "        return pd.DataFrame()\n",
        "\n",
        "\n",
        "def categorise_data(back_data, forward_data, halfsquat_data, still_data):\n",
        "\n",
        "    all_data = pd.concat([back_data, forward_data, halfsquat_data, still_data], axis=0)\n",
        "    # Create a list of categories based on the number of rows in each original dataframe\n",
        "    num_back_rows = back_data.shape[0]\n",
        "    num_forward_rows = forward_data.shape[0]\n",
        "    num_halfsquat_rows = halfsquat_data.shape[0]\n",
        "    num_still_rows = still_data.shape[0]\n",
        "\n",
        "    categories = ['back'] * num_back_rows + ['forward'] * num_forward_rows + ['halfsquat'] * num_halfsquat_rows + ['still'] * num_still_rows\n",
        "\n",
        "    # Add the 'category' column to the concatenated dataframe\n",
        "    all_data['category'] = categories\n",
        "    return all_data\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h-RoNGRVWaQn"
      },
      "source": [
        "## Sliding window"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "icF5KVcnAlXK"
      },
      "source": [
        "### EMG"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "szBJVq5ptUMy"
      },
      "source": [
        "#### Calculate RMS, WL, SSC ZC for each sliding window"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this section, we calculate the features **RMS** (Root Mean Square), **WL** (Waveform Length), **SSC** (Slope Sign Changes), and **ZC** (Zero Crossings) as described in the research paper. The functions for these calculations are presented below:\n"
      ],
      "metadata": {
        "id": "hdDm9vtpYl7V"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MDeqv6xZssse"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# Calcul des caractéristiques EMG\n",
        "def compute_rms(signal):\n",
        "    return np.sqrt(np.mean(signal**2))\n",
        "\n",
        "def compute_waveform_length(signal):\n",
        "    return np.sum(np.abs(np.diff(signal)))\n",
        "\n",
        "def compute_slope_sign_changes(signal):\n",
        "    # Compte les changements de signe de la pente\n",
        "    slope = np.diff(signal)\n",
        "    return np.sum(np.diff(np.sign(slope)) != 0)\n",
        "\n",
        "def compute_zero_crossings(signal):\n",
        "    # Compte les traversées de l'axe des abscisses\n",
        "    return np.sum(np.diff(np.sign(signal)) != 0)\n",
        "\n",
        "def extract_emg_features(window_data):\n",
        "    features = []\n",
        "    for col in ['R_Vlat', 'R_RF', 'R_ST', 'R_TA', 'L_Vlat', 'L_RF', 'L_ST', 'L_TA',\n",
        "       'R_MG', 'R_LG', 'R_SOL', 'R_IL', 'L_MG', 'L_LG', 'L_SOL', 'L_IL']:\n",
        "        signal = window_data[col].values\n",
        "\n",
        "        # Calcul des 4 caractéristiques pour chaque signal EMG\n",
        "        rms = compute_rms(signal)\n",
        "        wl = compute_waveform_length(signal)\n",
        "        ssc = compute_slope_sign_changes(signal)\n",
        "        zc = compute_zero_crossings(signal)\n",
        "\n",
        "        features.extend([rms, wl, ssc, zc])  # Ajouter les 4 caractéristiques pour chaque capteur\n",
        "\n",
        "    return features\n",
        "\n",
        "def sliding_window_segmentation_emg(df, window_samples, step_size):\n",
        "    \"\"\"\n",
        "    Découpe les données en fenêtres glissantes et extrait les caractéristiques EMG.\n",
        "\n",
        "    Args:\n",
        "    - df : DataFrame contenant les données, y compris les signaux EMG et les labels (category).\n",
        "    - window_samples : Taille de la fenêtre (en nombre de points).\n",
        "    - step_size : Pas de glissement (en nombre de points).\n",
        "\n",
        "    Returns:\n",
        "    - segmented_df : DataFrame avec les fenêtres segmentées et les labels.\n",
        "    \"\"\"\n",
        "    segmented_data = []\n",
        "\n",
        "    # Assurez-vous que les catégories sont traitées séparément\n",
        "    for category in df['category'].unique():\n",
        "        category_df = df[df['category'] == category]\n",
        "\n",
        "        # Découpage des données en fenêtres\n",
        "        for start in range(0, len(category_df) - window_samples + 1, step_size):\n",
        "            end = start + window_samples\n",
        "            window_data = category_df.iloc[start:end]\n",
        "\n",
        "            # Extraire les caractéristiques EMG de la fenêtre\n",
        "            emg_features = extract_emg_features(window_data)\n",
        "\n",
        "            # Ajouter la catégorie de cette fenêtre\n",
        "            emg_features.append(category)\n",
        "\n",
        "            segmented_data.append(emg_features)\n",
        "\n",
        "    # Créer un DataFrame avec les données segmentées\n",
        "    column_names = [col + \"_rms\" for col in ['R_Vlat', 'R_RF', 'R_ST', 'R_TA', 'L_Vlat', 'L_RF', 'L_ST', 'L_TA',\n",
        "       'R_MG', 'R_LG', 'R_SOL', 'R_IL', 'L_MG', 'L_LG', 'L_SOL', 'L_IL']] + \\\n",
        "                    [col + \"_wl\" for col in ['R_Vlat', 'R_RF', 'R_ST', 'R_TA', 'L_Vlat', 'L_RF', 'L_ST', 'L_TA',\n",
        "       'R_MG', 'R_LG', 'R_SOL', 'R_IL', 'L_MG', 'L_LG', 'L_SOL', 'L_IL']] + \\\n",
        "                    [col + \"_ssc\" for col in ['R_Vlat', 'R_RF', 'R_ST', 'R_TA', 'L_Vlat', 'L_RF', 'L_ST', 'L_TA',\n",
        "       'R_MG', 'R_LG', 'R_SOL', 'R_IL', 'L_MG', 'L_LG', 'L_SOL', 'L_IL']] + \\\n",
        "                    [col + \"_zc\" for col in ['R_Vlat', 'R_RF', 'R_ST', 'R_TA', 'L_Vlat', 'L_RF', 'L_ST', 'L_TA',\n",
        "       'R_MG', 'R_LG', 'R_SOL', 'R_IL', 'L_MG', 'L_LG', 'L_SOL', 'L_IL']] + \\\n",
        "                    ['category']\n",
        "\n",
        "    segmented_df = pd.DataFrame(segmented_data, columns=column_names)\n",
        "\n",
        "    return segmented_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qz1F_WYjA1Fw"
      },
      "source": [
        "## IMU et IPS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KmHTKv-IA0fA"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Function to compute mean for IMU and IPS\n",
        "def compute_mean(signal):\n",
        "    return np.mean(signal)\n",
        "\n",
        "# Function to extract features for IMU and IPS\n",
        "def extract_imu_ips_features(window_data, sensors):\n",
        "    features = []\n",
        "    for sensor in sensors:\n",
        "        signal = window_data[sensor].values\n",
        "        feature = compute_mean(signal)  # Mean value for each sensor's axis\n",
        "        features.append(feature)\n",
        "    return features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pIOzMVGWIcsZ"
      },
      "outputs": [],
      "source": [
        "# Function for sliding window segmentation for IMU and IPS data\n",
        "def sliding_window_segmentation_imu_ips(df, window_samples, step_size):\n",
        "\n",
        "    \"\"\"\n",
        "    Découpe les données en fenêtres glissantes et extrait les caractéristiques EMG.\n",
        "\n",
        "    Args:\n",
        "    - df : DataFrame contenant les données, y compris les signaux EMG et les labels (category).\n",
        "    - window_samples : Taille de la fenêtre (en nombre de points).\n",
        "    - step_size : Pas de glissement (en nombre de points).\n",
        "\n",
        "    Returns:\n",
        "    - segmented_df : DataFrame avec les fenêtres segmentées et les labels.\n",
        "    \"\"\"\n",
        "\n",
        "    segmented_data = []\n",
        "    sensors = (df.columns).to_list()\n",
        "    sensors.remove('category')\n",
        "    # Iterate through all data and segment it based on categories\n",
        "    for category in df['category'].unique():\n",
        "        category_df = df[df['category'] == category]\n",
        "\n",
        "        # Sliding window segmentation for IMU and IPS\n",
        "        for start in range(0, len(category_df) - window_samples + 1, step_size):\n",
        "            end = start + window_samples\n",
        "            window_data = category_df.iloc[start:end]\n",
        "            # Extract IMU features\n",
        "            features = extract_imu_ips_features(window_data, sensors)\n",
        "            # Ajouter la catégorie de cette fenêtre\n",
        "            features.append(category)\n",
        "            segmented_data.append(features)\n",
        "\n",
        "    # Create a DataFrame with the segmented data\n",
        "    feature_columns = [f'{sensor}_mean' for sensor in sensors] + \\\n",
        "                      ['category']\n",
        "\n",
        "    segmented_df = pd.DataFrame(segmented_data, columns=feature_columns)\n",
        "\n",
        "    return segmented_df\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GQ_lBQR0T_ld"
      },
      "source": [
        "### MoCap"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the doc : the mean value of re-referenced coordinates for each sensor within each sliding window was extracted as a feature."
      ],
      "metadata": {
        "id": "4pL8ef7KRWK4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VtPqqBm0jaB_"
      },
      "outputs": [],
      "source": [
        "def extract_mocap_features(window_data, sensors_referenced, sensors_velocity):\n",
        "\n",
        "    \"\"\"\n",
        "    Extracts motion capture (MoCap) features from a given window of data.\n",
        "\n",
        "    Parameters:\n",
        "        window_data (pd.DataFrame): A DataFrame containing sensor data for a single time window.\n",
        "\n",
        "        sensors_referenced (list of str): A list of sensor names (excluding reference sensors)\n",
        "                                          used for re-referenced coordinate features.\n",
        "        sensors_velocity (list of str): A list of sensor names (including reference sensors)\n",
        "                                        used for velocity-based features.\n",
        "\n",
        "    Returns:\n",
        "        list: A list of extracted features including:\n",
        "              - Mean of re-referenced coordinates for each axis of each sensor in `sensors_referenced`.\n",
        "              - Mean velocity for each axis of each sensor in `sensors_velocity`.\n",
        "    \"\"\"\n",
        "    features = []\n",
        "\n",
        "    # Re-referenced coordinate features (exclude reference sensor)\n",
        "    for sensor in sensors_referenced:\n",
        "        for axis in ['x', 'y', 'z']:\n",
        "            signal = window_data[f'{sensor}_{axis}'].values\n",
        "            features.append(np.mean(signal))  # Mean of re-referenced coordinates\n",
        "\n",
        "    # Velocity features (include reference sensor, including IJ)\n",
        "    for sensor in sensors_velocity:\n",
        "        for axis in ['x', 'y', 'z']:\n",
        "            signal = window_data[f'{sensor}_{axis}'].values\n",
        "            velocity = np.diff(signal)  # Derivative of coordinates\n",
        "            features.append(np.mean(velocity))  # Mean of velocity\n",
        "\n",
        "    return features\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qbFTMBESja25"
      },
      "outputs": [],
      "source": [
        "\n",
        "def sliding_window_segmentation_mocap(df, window_samples, step_size):\n",
        "\n",
        "    \"\"\"\n",
        "    Performs sliding window segmentation on motion capture (MoCap) data and extracts features for each window.\n",
        "\n",
        "    Parameters:\n",
        "        df (pd.DataFrame): A DataFrame containing motion capture data.\n",
        "        window_samples (int): The number of samples (rows) in each sliding window.\n",
        "        step_size (int): The step size (number of rows) to move the window for the next segment.\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: A DataFrame where each row corresponds to the features extracted from a window,\n",
        "                      and includes a 'category' column for the window's label. The columns are:\n",
        "                      - Mean features for each axis of sensors in `sensors_referenced`.\n",
        "                      - Mean velocity features for each axis of sensors in `sensors_velocity`.\n",
        "                      - The 'category' label of the window.\n",
        "    \"\"\"\n",
        "    segmented_data = []\n",
        "\n",
        "    reference_sensor = 'IJ'  # Replace 'IJ' with 'C7'\n",
        "\n",
        "    # List of available sensors (exclude '_x', '_y', '_z' duplicates)\n",
        "    available_sensors = [sensor[:-2] for sensor in df.columns if sensor.endswith('_x')]\n",
        "\n",
        "    # Separate sensors for re-referenced coordinates and velocities\n",
        "    sensors_referenced = [sensor for sensor in available_sensors if sensor != reference_sensor]\n",
        "    sensors_velocity = available_sensors  # Include all sensors, including IJ\n",
        "\n",
        "\n",
        "    for category in df['category'].unique():\n",
        "        category_df = df[df['category'] == category]\n",
        "\n",
        "        for start in range(0, len(category_df) - window_samples + 1, step_size):\n",
        "            end = start + window_samples\n",
        "            window_data = category_df.iloc[start:end]\n",
        "\n",
        "            # Extract features\n",
        "            features = extract_mocap_features(window_data, sensors_referenced, sensors_velocity)\n",
        "\n",
        "            # Append category label\n",
        "            features.append(category)\n",
        "            segmented_data.append(features)\n",
        "\n",
        "    # Feature column names\n",
        "    feature_columns = [\n",
        "        f'{sensor}_mean_{axis}' for sensor in sensors_referenced for axis in ['x', 'y', 'z']\n",
        "    ] + [\n",
        "        f'{sensor}_velocity_{axis}' for sensor in sensors_velocity for axis in ['x', 'y', 'z']\n",
        "    ] + ['category']\n",
        "\n",
        "    return pd.DataFrame(segmented_data, columns=feature_columns)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Run data preparition"
      ],
      "metadata": {
        "id": "X4s9h38FNqAb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this code, we chose to segment the data and create sliding windows for each person before concatenation. The only concatenation performed at this stage was, for instance, between emg_1 and emg_2 for each person. Throughout the process, we ensured that the category column names were preserved. Finally, we saved the processed data into separate files for each individual."
      ],
      "metadata": {
        "id": "yKp3TnzhbNDJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "def segment_and_save(data, segmentation_func, window_samples, step_size, save_path):\n",
        "    \"\"\"\n",
        "    Segment the data using the specified function and save to the given path.\n",
        "    \"\"\"\n",
        "    segmented_data = segmentation_func(data, window_samples, step_size)\n",
        "    if not os.path.exists(os.path.dirname(save_path)):\n",
        "        os.makedirs(os.path.dirname(save_path))\n",
        "    segmented_data.to_csv(save_path)\n",
        "    print(f\"Saved segmented data to: {save_path}\")\n",
        "\n",
        "def process_additional_files(dataset_path, signal, categorise_data, segmentation_funcs, segmentation_params):\n",
        "    \"\"\"\n",
        "    Detect and process additional files for a given signal in a dataset.\n",
        "    \"\"\"\n",
        "    activities = [\"back\", \"forward\", \"halfsquat\", \"still\"]\n",
        "    processed_files = set()\n",
        "\n",
        "    # Check for additional files dynamically\n",
        "    for activity in activities:\n",
        "        activity_path = os.path.join(dataset_path, activity)\n",
        "        if not os.path.exists(activity_path):\n",
        "            continue\n",
        "\n",
        "        for filename in os.listdir(activity_path):\n",
        "            match = re.match(rf\"({signal}_\\d+)\\.csv\", filename)\n",
        "            if match:\n",
        "                signal_name = match.group(1)\n",
        "\n",
        "                # Check if segmented file already exists\n",
        "                segmented_file_path = os.path.join(dataset_path, \"segmented_df\", f\"segmented_df_{signal_name}.csv\")\n",
        "                if os.path.exists(segmented_file_path):\n",
        "                    print(f\"Segmented file already exists for {signal_name}. Skipping processing.\")\n",
        "                    continue  # Skip if the segmented file already exists\n",
        "\n",
        "                # Collect data for this signal across activities\n",
        "                signal_data = {act: ensure_dataframe(os.path.join(dataset_path, act, f\"{signal_name}.csv\"))\n",
        "                               for act in activities}\n",
        "\n",
        "                # Combine and categorize\n",
        "                all_data = categorise_data(\n",
        "                    signal_data[\"back\"],\n",
        "                    signal_data[\"forward\"],\n",
        "                    signal_data[\"halfsquat\"],\n",
        "                    signal_data[\"still\"]\n",
        "                )\n",
        "\n",
        "                # Get segmentation function and parameters\n",
        "                params = segmentation_params.get(signal, {})\n",
        "                window_samples = int(params[\"window_size\"] * params[\"sampling_rate\"]) # seconds * frenquence of the captor\n",
        "                step_size = params[\"step_size\"]\n",
        "                save_path = os.path.join(dataset_path, \"segmented_df\", f\"segmented_df_{signal_name}.csv\")\n",
        "\n",
        "                # Determine the segmentation function\n",
        "                segmentation_func = segmentation_funcs.get(signal, None)\n",
        "                if segmentation_func:\n",
        "                    segment_and_save(all_data, segmentation_func, window_samples, step_size, save_path)\n",
        "\n",
        "                processed_files.add(signal_name)\n",
        "\n",
        "def load_dataset(num):\n",
        "    \"\"\"\n",
        "    Load and process data for a given dataset number, including additional signal files.\n",
        "    \"\"\"\n",
        "    dataset_path = f\".../Project/data/{num}/\"\n",
        "    signals = [\"emg\", \"imu\", \"ips\", \"mocap\"]\n",
        "\n",
        "    # Segmentation parameters for each signal type\n",
        "    segmentation_params = {\n",
        "        \"emg\": {\"sampling_rate\": 2000, \"window_size\": 0.05, \"step_size\": 100}, # for emg as mentioned in the document\n",
        "        \"imu\": {\"sampling_rate\": 100, \"window_size\": 0.05, \"step_size\": 5}, # for imu //\n",
        "        \"ips\": {\"sampling_rate\": 60, \"window_size\": 0.05, \"step_size\": 3}, # for ips //\n",
        "        \"mocap\": {\"sampling_rate\": 100, \"window_size\": 0.05, \"step_size\": 5}, # for //\n",
        "    }\n",
        "\n",
        "    # Segmentation functions for each signal type\n",
        "    segmentation_funcs = {\n",
        "        \"emg\": sliding_window_segmentation_emg,\n",
        "        \"imu\": sliding_window_segmentation_imu_ips,\n",
        "        \"ips\": sliding_window_segmentation_imu_ips,\n",
        "        \"mocap\": sliding_window_segmentation_mocap,\n",
        "    }\n",
        "\n",
        "    # Process primary files (e.g., emg_1, imu_1, etc.)\n",
        "    process_additional_files(dataset_path, \"emg\", categorise_data, segmentation_funcs, segmentation_params)\n",
        "    process_additional_files(dataset_path, \"imu\", categorise_data, segmentation_funcs, segmentation_params)\n",
        "    process_additional_files(dataset_path, \"ips\", categorise_data, segmentation_funcs, segmentation_params)\n",
        "    process_additional_files(dataset_path, \"mocap\", categorise_data, segmentation_funcs, segmentation_params)\n",
        "\n",
        "# Run for all dataset numbers\n",
        "for i in range(4, 26):\n",
        "    print(f\"Processing dataset {i}...\")\n",
        "    load_dataset(i)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZpW_MSm1u3dV",
        "outputId": "4df5d348-0fbb-4251-adfd-c3852637bffd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing dataset 4...\n",
            "Segmented file already exists for emg_1. Skipping processing.\n",
            "Segmented file already exists for emg_1. Skipping processing.\n",
            "Segmented file already exists for emg_1. Skipping processing.\n",
            "Segmented file already exists for emg_1. Skipping processing.\n",
            "Segmented file already exists for imu_1. Skipping processing.\n",
            "Segmented file already exists for imu_1. Skipping processing.\n",
            "Segmented file already exists for imu_1. Skipping processing.\n",
            "Segmented file already exists for imu_1. Skipping processing.\n",
            "Segmented file already exists for ips_1. Skipping processing.\n",
            "Segmented file already exists for ips_1. Skipping processing.\n",
            "Segmented file already exists for ips_1. Skipping processing.\n",
            "Segmented file already exists for ips_1. Skipping processing.\n",
            "Segmented file already exists for mocap_1. Skipping processing.\n",
            "Segmented file already exists for mocap_1. Skipping processing.\n",
            "Segmented file already exists for mocap_1. Skipping processing.\n",
            "Segmented file already exists for mocap_1. Skipping processing.\n",
            "Processing dataset 5...\n",
            "Segmented file already exists for emg_1. Skipping processing.\n",
            "Segmented file already exists for emg_1. Skipping processing.\n",
            "Segmented file already exists for emg_1. Skipping processing.\n",
            "Segmented file already exists for emg_1. Skipping processing.\n",
            "Segmented file already exists for imu_1. Skipping processing.\n",
            "Segmented file already exists for imu_1. Skipping processing.\n",
            "Segmented file already exists for imu_1. Skipping processing.\n",
            "Segmented file already exists for imu_1. Skipping processing.\n",
            "Segmented file already exists for ips_1. Skipping processing.\n",
            "Segmented file already exists for ips_1. Skipping processing.\n",
            "Segmented file already exists for ips_1. Skipping processing.\n",
            "Segmented file already exists for ips_1. Skipping processing.\n",
            "Segmented file already exists for mocap_1. Skipping processing.\n",
            "Segmented file already exists for mocap_1. Skipping processing.\n",
            "Segmented file already exists for mocap_1. Skipping processing.\n",
            "Segmented file already exists for mocap_1. Skipping processing.\n",
            "Processing dataset 6...\n",
            "Segmented file already exists for emg_1. Skipping processing.\n",
            "Segmented file already exists for emg_1. Skipping processing.\n",
            "Segmented file already exists for emg_1. Skipping processing.\n",
            "Segmented file already exists for emg_1. Skipping processing.\n",
            "Segmented file already exists for imu_1. Skipping processing.\n",
            "Segmented file already exists for imu_1. Skipping processing.\n",
            "Segmented file already exists for imu_1. Skipping processing.\n",
            "Segmented file already exists for imu_1. Skipping processing.\n",
            "Segmented file already exists for ips_1. Skipping processing.\n",
            "Segmented file already exists for ips_1. Skipping processing.\n",
            "Segmented file already exists for ips_1. Skipping processing.\n",
            "Segmented file already exists for ips_1. Skipping processing.\n",
            "Segmented file already exists for mocap_1. Skipping processing.\n",
            "Segmented file already exists for mocap_1. Skipping processing.\n",
            "Segmented file already exists for mocap_1. Skipping processing.\n",
            "Segmented file already exists for mocap_1. Skipping processing.\n",
            "Processing dataset 7...\n",
            "Segmented file already exists for emg_1. Skipping processing.\n",
            "Segmented file already exists for emg_1. Skipping processing.\n",
            "Segmented file already exists for emg_1. Skipping processing.\n",
            "Segmented file already exists for emg_1. Skipping processing.\n",
            "Segmented file already exists for imu_1. Skipping processing.\n",
            "Segmented file already exists for imu_1. Skipping processing.\n",
            "Segmented file already exists for imu_1. Skipping processing.\n",
            "Segmented file already exists for imu_1. Skipping processing.\n",
            "Segmented file already exists for ips_1. Skipping processing.\n",
            "Segmented file already exists for ips_1. Skipping processing.\n",
            "Segmented file already exists for ips_1. Skipping processing.\n",
            "Segmented file already exists for ips_1. Skipping processing.\n",
            "Segmented file already exists for mocap_1. Skipping processing.\n",
            "Segmented file already exists for mocap_1. Skipping processing.\n",
            "Segmented file already exists for mocap_1. Skipping processing.\n",
            "Segmented file already exists for mocap_1. Skipping processing.\n",
            "Processing dataset 8...\n",
            "Segmented file already exists for emg_1. Skipping processing.\n",
            "Segmented file already exists for emg_1. Skipping processing.\n",
            "File not found: /content/drive/My Drive/Master2_Paris8/Architecture complex/Project/data/8/back/emg_2.csv. Returning empty DataFrame.\n",
            "File not found: /content/drive/My Drive/Master2_Paris8/Architecture complex/Project/data/8/halfsquat/emg_2.csv. Returning empty DataFrame.\n",
            "File not found: /content/drive/My Drive/Master2_Paris8/Architecture complex/Project/data/8/still/emg_2.csv. Returning empty DataFrame.\n",
            "Saved segmented data to: /content/drive/My Drive/Master2_Paris8/Architecture complex/Project/data/8/segmented_df/segmented_df_emg_2.csv\n",
            "Segmented file already exists for emg_1. Skipping processing.\n",
            "Segmented file already exists for emg_1. Skipping processing.\n",
            "Segmented file already exists for imu_1. Skipping processing.\n",
            "Segmented file already exists for imu_1. Skipping processing.\n",
            "File not found: /content/drive/My Drive/Master2_Paris8/Architecture complex/Project/data/8/back/imu_2.csv. Returning empty DataFrame.\n",
            "File not found: /content/drive/My Drive/Master2_Paris8/Architecture complex/Project/data/8/halfsquat/imu_2.csv. Returning empty DataFrame.\n",
            "File not found: /content/drive/My Drive/Master2_Paris8/Architecture complex/Project/data/8/still/imu_2.csv. Returning empty DataFrame.\n",
            "Saved segmented data to: /content/drive/My Drive/Master2_Paris8/Architecture complex/Project/data/8/segmented_df/segmented_df_imu_2.csv\n",
            "Segmented file already exists for imu_1. Skipping processing.\n",
            "Segmented file already exists for imu_1. Skipping processing.\n",
            "Segmented file already exists for ips_1. Skipping processing.\n",
            "Segmented file already exists for ips_1. Skipping processing.\n",
            "File not found: /content/drive/My Drive/Master2_Paris8/Architecture complex/Project/data/8/back/ips_2.csv. Returning empty DataFrame.\n",
            "File not found: /content/drive/My Drive/Master2_Paris8/Architecture complex/Project/data/8/halfsquat/ips_2.csv. Returning empty DataFrame.\n",
            "File not found: /content/drive/My Drive/Master2_Paris8/Architecture complex/Project/data/8/still/ips_2.csv. Returning empty DataFrame.\n",
            "Saved segmented data to: /content/drive/My Drive/Master2_Paris8/Architecture complex/Project/data/8/segmented_df/segmented_df_ips_2.csv\n",
            "Segmented file already exists for ips_1. Skipping processing.\n",
            "Segmented file already exists for ips_1. Skipping processing.\n",
            "Segmented file already exists for mocap_1. Skipping processing.\n",
            "Segmented file already exists for mocap_1. Skipping processing.\n",
            "File not found: /content/drive/My Drive/Master2_Paris8/Architecture complex/Project/data/8/back/mocap_2.csv. Returning empty DataFrame.\n",
            "File not found: /content/drive/My Drive/Master2_Paris8/Architecture complex/Project/data/8/halfsquat/mocap_2.csv. Returning empty DataFrame.\n",
            "File not found: /content/drive/My Drive/Master2_Paris8/Architecture complex/Project/data/8/still/mocap_2.csv. Returning empty DataFrame.\n",
            "Saved segmented data to: /content/drive/My Drive/Master2_Paris8/Architecture complex/Project/data/8/segmented_df/segmented_df_mocap_2.csv\n",
            "Segmented file already exists for mocap_1. Skipping processing.\n",
            "Segmented file already exists for mocap_1. Skipping processing.\n",
            "Processing dataset 9...\n",
            "Segmented file already exists for emg_1. Skipping processing.\n",
            "Segmented file already exists for emg_1. Skipping processing.\n",
            "Segmented file already exists for emg_1. Skipping processing.\n",
            "Segmented file already exists for emg_1. Skipping processing.\n",
            "Segmented file already exists for imu_1. Skipping processing.\n",
            "Segmented file already exists for imu_1. Skipping processing.\n",
            "Segmented file already exists for imu_1. Skipping processing.\n",
            "Segmented file already exists for imu_1. Skipping processing.\n",
            "Segmented file already exists for ips_1. Skipping processing.\n",
            "Segmented file already exists for ips_1. Skipping processing.\n",
            "Segmented file already exists for ips_1. Skipping processing.\n",
            "Segmented file already exists for ips_1. Skipping processing.\n",
            "Segmented file already exists for mocap_1. Skipping processing.\n",
            "Segmented file already exists for mocap_1. Skipping processing.\n",
            "Segmented file already exists for mocap_1. Skipping processing.\n",
            "Segmented file already exists for mocap_1. Skipping processing.\n",
            "Processing dataset 10...\n",
            "Segmented file already exists for emg_1. Skipping processing.\n",
            "Segmented file already exists for emg_1. Skipping processing.\n",
            "Segmented file already exists for emg_1. Skipping processing.\n",
            "Segmented file already exists for emg_1. Skipping processing.\n",
            "Segmented file already exists for imu_1. Skipping processing.\n",
            "Segmented file already exists for imu_1. Skipping processing.\n",
            "Segmented file already exists for imu_1. Skipping processing.\n",
            "Segmented file already exists for imu_1. Skipping processing.\n",
            "Segmented file already exists for ips_1. Skipping processing.\n",
            "Segmented file already exists for ips_1. Skipping processing.\n",
            "Segmented file already exists for ips_1. Skipping processing.\n",
            "Segmented file already exists for ips_1. Skipping processing.\n",
            "Segmented file already exists for mocap_1. Skipping processing.\n",
            "Segmented file already exists for mocap_1. Skipping processing.\n",
            "Segmented file already exists for mocap_1. Skipping processing.\n",
            "Segmented file already exists for mocap_1. Skipping processing.\n",
            "Processing dataset 11...\n",
            "Segmented file already exists for emg_1. Skipping processing.\n",
            "Segmented file already exists for emg_1. Skipping processing.\n",
            "Segmented file already exists for emg_1. Skipping processing.\n",
            "Segmented file already exists for emg_1. Skipping processing.\n",
            "Segmented file already exists for imu_1. Skipping processing.\n",
            "Segmented file already exists for imu_1. Skipping processing.\n",
            "Segmented file already exists for imu_1. Skipping processing.\n",
            "Segmented file already exists for imu_1. Skipping processing.\n",
            "Segmented file already exists for ips_1. Skipping processing.\n",
            "Segmented file already exists for ips_1. Skipping processing.\n",
            "Segmented file already exists for ips_1. Skipping processing.\n",
            "Segmented file already exists for ips_1. Skipping processing.\n",
            "Segmented file already exists for mocap_1. Skipping processing.\n",
            "Segmented file already exists for mocap_1. Skipping processing.\n",
            "Segmented file already exists for mocap_1. Skipping processing.\n",
            "Segmented file already exists for mocap_1. Skipping processing.\n",
            "Processing dataset 12...\n",
            "Segmented file already exists for emg_1. Skipping processing.\n",
            "Segmented file already exists for emg_1. Skipping processing.\n",
            "Segmented file already exists for emg_1. Skipping processing.\n",
            "Segmented file already exists for emg_1. Skipping processing.\n",
            "Segmented file already exists for imu_1. Skipping processing.\n",
            "Segmented file already exists for imu_1. Skipping processing.\n",
            "Segmented file already exists for imu_1. Skipping processing.\n",
            "Segmented file already exists for imu_1. Skipping processing.\n",
            "Segmented file already exists for ips_1. Skipping processing.\n",
            "Segmented file already exists for ips_1. Skipping processing.\n",
            "Segmented file already exists for ips_1. Skipping processing.\n",
            "Segmented file already exists for ips_1. Skipping processing.\n",
            "Segmented file already exists for mocap_1. Skipping processing.\n",
            "Segmented file already exists for mocap_1. Skipping processing.\n",
            "Segmented file already exists for mocap_1. Skipping processing.\n",
            "Segmented file already exists for mocap_1. Skipping processing.\n",
            "Processing dataset 13...\n",
            "Segmented file already exists for emg_1. Skipping processing.\n",
            "Segmented file already exists for emg_1. Skipping processing.\n",
            "Segmented file already exists for emg_1. Skipping processing.\n",
            "Segmented file already exists for emg_1. Skipping processing.\n",
            "Segmented file already exists for imu_1. Skipping processing.\n",
            "Segmented file already exists for imu_1. Skipping processing.\n",
            "Segmented file already exists for imu_1. Skipping processing.\n",
            "Segmented file already exists for imu_1. Skipping processing.\n",
            "Segmented file already exists for ips_1. Skipping processing.\n",
            "Segmented file already exists for ips_1. Skipping processing.\n",
            "Segmented file already exists for ips_1. Skipping processing.\n",
            "Segmented file already exists for ips_1. Skipping processing.\n",
            "Segmented file already exists for mocap_1. Skipping processing.\n",
            "Segmented file already exists for mocap_1. Skipping processing.\n",
            "Segmented file already exists for mocap_1. Skipping processing.\n",
            "Segmented file already exists for mocap_1. Skipping processing.\n",
            "Processing dataset 14...\n",
            "Segmented file already exists for emg_1. Skipping processing.\n",
            "Segmented file already exists for emg_1. Skipping processing.\n",
            "Segmented file already exists for emg_1. Skipping processing.\n",
            "Segmented file already exists for emg_1. Skipping processing.\n",
            "Segmented file already exists for imu_1. Skipping processing.\n",
            "Segmented file already exists for imu_1. Skipping processing.\n",
            "Segmented file already exists for imu_1. Skipping processing.\n",
            "Segmented file already exists for imu_1. Skipping processing.\n",
            "Segmented file already exists for ips_1. Skipping processing.\n",
            "Segmented file already exists for ips_1. Skipping processing.\n",
            "Segmented file already exists for ips_1. Skipping processing.\n",
            "Segmented file already exists for ips_1. Skipping processing.\n",
            "Segmented file already exists for mocap_1. Skipping processing.\n",
            "Segmented file already exists for mocap_1. Skipping processing.\n",
            "Segmented file already exists for mocap_1. Skipping processing.\n",
            "Segmented file already exists for mocap_1. Skipping processing.\n",
            "Processing dataset 15...\n",
            "Segmented file already exists for emg_1. Skipping processing.\n",
            "File not found: /content/drive/My Drive/Master2_Paris8/Architecture complex/Project/data/15/forward/emg_2.csv. Returning empty DataFrame.\n",
            "File not found: /content/drive/My Drive/Master2_Paris8/Architecture complex/Project/data/15/halfsquat/emg_2.csv. Returning empty DataFrame.\n",
            "File not found: /content/drive/My Drive/Master2_Paris8/Architecture complex/Project/data/15/still/emg_2.csv. Returning empty DataFrame.\n",
            "Saved segmented data to: /content/drive/My Drive/Master2_Paris8/Architecture complex/Project/data/15/segmented_df/segmented_df_emg_2.csv\n",
            "Segmented file already exists for emg_1. Skipping processing.\n",
            "Segmented file already exists for emg_1. Skipping processing.\n",
            "Segmented file already exists for emg_1. Skipping processing.\n",
            "Segmented file already exists for imu_1. Skipping processing.\n",
            "File not found: /content/drive/My Drive/Master2_Paris8/Architecture complex/Project/data/15/forward/imu_2.csv. Returning empty DataFrame.\n",
            "File not found: /content/drive/My Drive/Master2_Paris8/Architecture complex/Project/data/15/halfsquat/imu_2.csv. Returning empty DataFrame.\n",
            "File not found: /content/drive/My Drive/Master2_Paris8/Architecture complex/Project/data/15/still/imu_2.csv. Returning empty DataFrame.\n",
            "Saved segmented data to: /content/drive/My Drive/Master2_Paris8/Architecture complex/Project/data/15/segmented_df/segmented_df_imu_2.csv\n",
            "Segmented file already exists for imu_1. Skipping processing.\n",
            "Segmented file already exists for imu_1. Skipping processing.\n",
            "Segmented file already exists for imu_1. Skipping processing.\n",
            "Segmented file already exists for ips_1. Skipping processing.\n",
            "File not found: /content/drive/My Drive/Master2_Paris8/Architecture complex/Project/data/15/forward/ips_2.csv. Returning empty DataFrame.\n",
            "File not found: /content/drive/My Drive/Master2_Paris8/Architecture complex/Project/data/15/halfsquat/ips_2.csv. Returning empty DataFrame.\n",
            "File not found: /content/drive/My Drive/Master2_Paris8/Architecture complex/Project/data/15/still/ips_2.csv. Returning empty DataFrame.\n",
            "Saved segmented data to: /content/drive/My Drive/Master2_Paris8/Architecture complex/Project/data/15/segmented_df/segmented_df_ips_2.csv\n",
            "Segmented file already exists for ips_1. Skipping processing.\n",
            "Segmented file already exists for ips_1. Skipping processing.\n",
            "Segmented file already exists for ips_1. Skipping processing.\n",
            "Segmented file already exists for mocap_1. Skipping processing.\n",
            "File not found: /content/drive/My Drive/Master2_Paris8/Architecture complex/Project/data/15/forward/mocap_2.csv. Returning empty DataFrame.\n",
            "File not found: /content/drive/My Drive/Master2_Paris8/Architecture complex/Project/data/15/halfsquat/mocap_2.csv. Returning empty DataFrame.\n",
            "File not found: /content/drive/My Drive/Master2_Paris8/Architecture complex/Project/data/15/still/mocap_2.csv. Returning empty DataFrame.\n",
            "Saved segmented data to: /content/drive/My Drive/Master2_Paris8/Architecture complex/Project/data/15/segmented_df/segmented_df_mocap_2.csv\n",
            "Segmented file already exists for mocap_1. Skipping processing.\n",
            "Segmented file already exists for mocap_1. Skipping processing.\n",
            "Segmented file already exists for mocap_1. Skipping processing.\n",
            "Processing dataset 16...\n",
            "Segmented file already exists for emg_1. Skipping processing.\n",
            "Segmented file already exists for emg_1. Skipping processing.\n",
            "Segmented file already exists for emg_1. Skipping processing.\n",
            "Segmented file already exists for emg_1. Skipping processing.\n",
            "Segmented file already exists for imu_1. Skipping processing.\n",
            "Segmented file already exists for imu_1. Skipping processing.\n",
            "Segmented file already exists for imu_1. Skipping processing.\n",
            "Segmented file already exists for imu_1. Skipping processing.\n",
            "Segmented file already exists for ips_1. Skipping processing.\n",
            "Segmented file already exists for ips_1. Skipping processing.\n",
            "Segmented file already exists for ips_1. Skipping processing.\n",
            "Segmented file already exists for ips_1. Skipping processing.\n",
            "Segmented file already exists for mocap_1. Skipping processing.\n",
            "Segmented file already exists for mocap_1. Skipping processing.\n",
            "Segmented file already exists for mocap_1. Skipping processing.\n",
            "Segmented file already exists for mocap_1. Skipping processing.\n",
            "Processing dataset 17...\n",
            "Segmented file already exists for emg_1. Skipping processing.\n",
            "Segmented file already exists for emg_1. Skipping processing.\n",
            "Segmented file already exists for emg_1. Skipping processing.\n",
            "Segmented file already exists for emg_1. Skipping processing.\n",
            "Segmented file already exists for imu_1. Skipping processing.\n",
            "Segmented file already exists for imu_1. Skipping processing.\n",
            "Segmented file already exists for imu_1. Skipping processing.\n",
            "Segmented file already exists for imu_1. Skipping processing.\n",
            "Segmented file already exists for ips_1. Skipping processing.\n",
            "Segmented file already exists for ips_1. Skipping processing.\n",
            "Segmented file already exists for ips_1. Skipping processing.\n",
            "Segmented file already exists for ips_1. Skipping processing.\n",
            "Segmented file already exists for mocap_1. Skipping processing.\n",
            "Segmented file already exists for mocap_1. Skipping processing.\n",
            "Segmented file already exists for mocap_1. Skipping processing.\n",
            "Segmented file already exists for mocap_1. Skipping processing.\n",
            "Processing dataset 18...\n",
            "Segmented file already exists for emg_1. Skipping processing.\n",
            "Segmented file already exists for emg_1. Skipping processing.\n",
            "Segmented file already exists for emg_1. Skipping processing.\n",
            "Segmented file already exists for imu_1. Skipping processing.\n",
            "Segmented file already exists for imu_1. Skipping processing.\n",
            "Segmented file already exists for imu_1. Skipping processing.\n",
            "Segmented file already exists for ips_1. Skipping processing.\n",
            "Segmented file already exists for ips_1. Skipping processing.\n",
            "Segmented file already exists for ips_1. Skipping processing.\n",
            "Segmented file already exists for mocap_1. Skipping processing.\n",
            "Segmented file already exists for mocap_1. Skipping processing.\n",
            "Segmented file already exists for mocap_1. Skipping processing.\n",
            "Processing dataset 19...\n",
            "Segmented file already exists for emg_1. Skipping processing.\n",
            "Segmented file already exists for emg_1. Skipping processing.\n",
            "Segmented file already exists for emg_1. Skipping processing.\n",
            "Segmented file already exists for imu_1. Skipping processing.\n",
            "Segmented file already exists for imu_1. Skipping processing.\n",
            "Segmented file already exists for imu_1. Skipping processing.\n",
            "Segmented file already exists for ips_1. Skipping processing.\n",
            "Segmented file already exists for ips_1. Skipping processing.\n",
            "Segmented file already exists for ips_1. Skipping processing.\n",
            "Segmented file already exists for mocap_1. Skipping processing.\n",
            "Segmented file already exists for mocap_1. Skipping processing.\n",
            "Segmented file already exists for mocap_1. Skipping processing.\n",
            "Processing dataset 20...\n",
            "Segmented file already exists for emg_1. Skipping processing.\n",
            "Segmented file already exists for emg_1. Skipping processing.\n",
            "Segmented file already exists for emg_1. Skipping processing.\n",
            "File not found: /content/drive/My Drive/Master2_Paris8/Architecture complex/Project/data/20/back/emg_2.csv. Returning empty DataFrame.\n",
            "File not found: /content/drive/My Drive/Master2_Paris8/Architecture complex/Project/data/20/forward/emg_2.csv. Returning empty DataFrame.\n",
            "File not found: /content/drive/My Drive/Master2_Paris8/Architecture complex/Project/data/20/halfsquat/emg_2.csv. Returning empty DataFrame.\n",
            "Saved segmented data to: /content/drive/My Drive/Master2_Paris8/Architecture complex/Project/data/20/segmented_df/segmented_df_emg_2.csv\n",
            "Segmented file already exists for imu_1. Skipping processing.\n",
            "Segmented file already exists for imu_1. Skipping processing.\n",
            "Segmented file already exists for imu_1. Skipping processing.\n",
            "File not found: /content/drive/My Drive/Master2_Paris8/Architecture complex/Project/data/20/back/imu_2.csv. Returning empty DataFrame.\n",
            "File not found: /content/drive/My Drive/Master2_Paris8/Architecture complex/Project/data/20/forward/imu_2.csv. Returning empty DataFrame.\n",
            "File not found: /content/drive/My Drive/Master2_Paris8/Architecture complex/Project/data/20/halfsquat/imu_2.csv. Returning empty DataFrame.\n",
            "Saved segmented data to: /content/drive/My Drive/Master2_Paris8/Architecture complex/Project/data/20/segmented_df/segmented_df_imu_2.csv\n",
            "Segmented file already exists for ips_1. Skipping processing.\n",
            "Segmented file already exists for ips_1. Skipping processing.\n",
            "Segmented file already exists for ips_1. Skipping processing.\n",
            "File not found: /content/drive/My Drive/Master2_Paris8/Architecture complex/Project/data/20/back/ips_2.csv. Returning empty DataFrame.\n",
            "File not found: /content/drive/My Drive/Master2_Paris8/Architecture complex/Project/data/20/forward/ips_2.csv. Returning empty DataFrame.\n",
            "File not found: /content/drive/My Drive/Master2_Paris8/Architecture complex/Project/data/20/halfsquat/ips_2.csv. Returning empty DataFrame.\n",
            "Saved segmented data to: /content/drive/My Drive/Master2_Paris8/Architecture complex/Project/data/20/segmented_df/segmented_df_ips_2.csv\n",
            "Segmented file already exists for mocap_1. Skipping processing.\n",
            "Segmented file already exists for mocap_1. Skipping processing.\n",
            "Segmented file already exists for mocap_1. Skipping processing.\n",
            "File not found: /content/drive/My Drive/Master2_Paris8/Architecture complex/Project/data/20/back/mocap_2.csv. Returning empty DataFrame.\n",
            "File not found: /content/drive/My Drive/Master2_Paris8/Architecture complex/Project/data/20/forward/mocap_2.csv. Returning empty DataFrame.\n",
            "File not found: /content/drive/My Drive/Master2_Paris8/Architecture complex/Project/data/20/halfsquat/mocap_2.csv. Returning empty DataFrame.\n",
            "Saved segmented data to: /content/drive/My Drive/Master2_Paris8/Architecture complex/Project/data/20/segmented_df/segmented_df_mocap_2.csv\n",
            "Processing dataset 21...\n",
            "Segmented file already exists for emg_1. Skipping processing.\n",
            "Segmented file already exists for emg_1. Skipping processing.\n",
            "Segmented file already exists for emg_1. Skipping processing.\n",
            "Segmented file already exists for imu_1. Skipping processing.\n",
            "Segmented file already exists for imu_1. Skipping processing.\n",
            "Segmented file already exists for imu_1. Skipping processing.\n",
            "Segmented file already exists for ips_1. Skipping processing.\n",
            "Segmented file already exists for ips_1. Skipping processing.\n",
            "Segmented file already exists for ips_1. Skipping processing.\n",
            "Segmented file already exists for mocap_1. Skipping processing.\n",
            "Segmented file already exists for mocap_1. Skipping processing.\n",
            "Segmented file already exists for mocap_1. Skipping processing.\n",
            "Processing dataset 22...\n",
            "Segmented file already exists for emg_1. Skipping processing.\n",
            "Segmented file already exists for emg_1. Skipping processing.\n",
            "Segmented file already exists for emg_1. Skipping processing.\n",
            "Segmented file already exists for imu_1. Skipping processing.\n",
            "Segmented file already exists for imu_1. Skipping processing.\n",
            "Segmented file already exists for imu_1. Skipping processing.\n",
            "Segmented file already exists for ips_1. Skipping processing.\n",
            "Segmented file already exists for ips_1. Skipping processing.\n",
            "Segmented file already exists for ips_1. Skipping processing.\n",
            "Segmented file already exists for mocap_1. Skipping processing.\n",
            "Segmented file already exists for mocap_1. Skipping processing.\n",
            "Segmented file already exists for mocap_1. Skipping processing.\n",
            "Processing dataset 23...\n",
            "Segmented file already exists for emg_1. Skipping processing.\n",
            "Segmented file already exists for emg_1. Skipping processing.\n",
            "Segmented file already exists for imu_1. Skipping processing.\n",
            "Segmented file already exists for imu_1. Skipping processing.\n",
            "Segmented file already exists for ips_1. Skipping processing.\n",
            "Segmented file already exists for ips_1. Skipping processing.\n",
            "Segmented file already exists for mocap_1. Skipping processing.\n",
            "Segmented file already exists for mocap_1. Skipping processing.\n",
            "Processing dataset 24...\n",
            "Segmented file already exists for emg_1. Skipping processing.\n",
            "Segmented file already exists for emg_1. Skipping processing.\n",
            "Segmented file already exists for emg_1. Skipping processing.\n",
            "Segmented file already exists for imu_1. Skipping processing.\n",
            "Segmented file already exists for imu_1. Skipping processing.\n",
            "Segmented file already exists for imu_1. Skipping processing.\n",
            "Segmented file already exists for ips_1. Skipping processing.\n",
            "Segmented file already exists for ips_1. Skipping processing.\n",
            "Segmented file already exists for ips_1. Skipping processing.\n",
            "Segmented file already exists for mocap_1. Skipping processing.\n",
            "Segmented file already exists for mocap_1. Skipping processing.\n",
            "Segmented file already exists for mocap_1. Skipping processing.\n",
            "Processing dataset 25...\n",
            "Segmented file already exists for emg_1. Skipping processing.\n",
            "File not found: /content/drive/My Drive/Master2_Paris8/Architecture complex/Project/data/25/halfsquat/emg_2.csv. Returning empty DataFrame.\n",
            "Saved segmented data to: /content/drive/My Drive/Master2_Paris8/Architecture complex/Project/data/25/segmented_df/segmented_df_emg_2.csv\n",
            "File not found: /content/drive/My Drive/Master2_Paris8/Architecture complex/Project/data/25/forward/emg_3.csv. Returning empty DataFrame.\n",
            "File not found: /content/drive/My Drive/Master2_Paris8/Architecture complex/Project/data/25/halfsquat/emg_3.csv. Returning empty DataFrame.\n",
            "Saved segmented data to: /content/drive/My Drive/Master2_Paris8/Architecture complex/Project/data/25/segmented_df/segmented_df_emg_3.csv\n",
            "Segmented file already exists for emg_1. Skipping processing.\n",
            "Segmented file already exists for emg_2. Skipping processing.\n",
            "Segmented file already exists for emg_1. Skipping processing.\n",
            "Segmented file already exists for emg_1. Skipping processing.\n",
            "Segmented file already exists for emg_2. Skipping processing.\n",
            "Segmented file already exists for emg_3. Skipping processing.\n",
            "Segmented file already exists for imu_1. Skipping processing.\n",
            "File not found: /content/drive/My Drive/Master2_Paris8/Architecture complex/Project/data/25/halfsquat/imu_2.csv. Returning empty DataFrame.\n",
            "Saved segmented data to: /content/drive/My Drive/Master2_Paris8/Architecture complex/Project/data/25/segmented_df/segmented_df_imu_2.csv\n",
            "File not found: /content/drive/My Drive/Master2_Paris8/Architecture complex/Project/data/25/forward/imu_3.csv. Returning empty DataFrame.\n",
            "File not found: /content/drive/My Drive/Master2_Paris8/Architecture complex/Project/data/25/halfsquat/imu_3.csv. Returning empty DataFrame.\n",
            "Saved segmented data to: /content/drive/My Drive/Master2_Paris8/Architecture complex/Project/data/25/segmented_df/segmented_df_imu_3.csv\n",
            "Segmented file already exists for imu_1. Skipping processing.\n",
            "Segmented file already exists for imu_2. Skipping processing.\n",
            "Segmented file already exists for imu_1. Skipping processing.\n",
            "Segmented file already exists for imu_1. Skipping processing.\n",
            "Segmented file already exists for imu_2. Skipping processing.\n",
            "Segmented file already exists for imu_3. Skipping processing.\n",
            "Segmented file already exists for ips_1. Skipping processing.\n",
            "File not found: /content/drive/My Drive/Master2_Paris8/Architecture complex/Project/data/25/halfsquat/ips_2.csv. Returning empty DataFrame.\n",
            "Saved segmented data to: /content/drive/My Drive/Master2_Paris8/Architecture complex/Project/data/25/segmented_df/segmented_df_ips_2.csv\n",
            "File not found: /content/drive/My Drive/Master2_Paris8/Architecture complex/Project/data/25/forward/ips_3.csv. Returning empty DataFrame.\n",
            "File not found: /content/drive/My Drive/Master2_Paris8/Architecture complex/Project/data/25/halfsquat/ips_3.csv. Returning empty DataFrame.\n",
            "Saved segmented data to: /content/drive/My Drive/Master2_Paris8/Architecture complex/Project/data/25/segmented_df/segmented_df_ips_3.csv\n",
            "Segmented file already exists for ips_1. Skipping processing.\n",
            "Segmented file already exists for ips_2. Skipping processing.\n",
            "Segmented file already exists for ips_1. Skipping processing.\n",
            "Segmented file already exists for ips_1. Skipping processing.\n",
            "Segmented file already exists for ips_2. Skipping processing.\n",
            "Segmented file already exists for ips_3. Skipping processing.\n",
            "File not found: /content/drive/My Drive/Master2_Paris8/Architecture complex/Project/data/25/forward/mocap_3.csv. Returning empty DataFrame.\n",
            "File not found: /content/drive/My Drive/Master2_Paris8/Architecture complex/Project/data/25/halfsquat/mocap_3.csv. Returning empty DataFrame.\n",
            "Saved segmented data to: /content/drive/My Drive/Master2_Paris8/Architecture complex/Project/data/25/segmented_df/segmented_df_mocap_3.csv\n",
            "File not found: /content/drive/My Drive/Master2_Paris8/Architecture complex/Project/data/25/halfsquat/mocap_2.csv. Returning empty DataFrame.\n",
            "Saved segmented data to: /content/drive/My Drive/Master2_Paris8/Architecture complex/Project/data/25/segmented_df/segmented_df_mocap_2.csv\n",
            "Segmented file already exists for mocap_1. Skipping processing.\n",
            "Segmented file already exists for mocap_1. Skipping processing.\n",
            "Segmented file already exists for mocap_2. Skipping processing.\n",
            "Segmented file already exists for mocap_1. Skipping processing.\n",
            "Segmented file already exists for mocap_1. Skipping processing.\n",
            "Segmented file already exists for mocap_3. Skipping processing.\n",
            "Segmented file already exists for mocap_2. Skipping processing.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Concat files with multiple emgs, ips..etc, example concat emg_1 and emg_2"
      ],
      "metadata": {
        "id": "jkUOcwzsOE-2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "def concatenate_files_in_directory(directory_path, prefixes):\n",
        "    \"\"\"\n",
        "    Concatenate files that match specific patterns (like segmented_df_emg_1, segmented_df_imu_1, etc.)\n",
        "\n",
        "    :param directory_path: The directory to scan for files\n",
        "    :param prefixes: List of prefixes to look for (e.g., ['segmented_df_emg', 'segmented_df_imu', 'segmented_df_ips', 'segmented_df_mocap'])\n",
        "    :return: A dictionary with concatenated data for each prefix.\n",
        "    \"\"\"\n",
        "    concatenated_data = {prefix: pd.DataFrame() for prefix in prefixes}\n",
        "\n",
        "    # List all files in the directory\n",
        "    for filename in os.listdir(directory_path):\n",
        "        for prefix in prefixes:\n",
        "            # Check if the filename contains the prefix and ends with .csv\n",
        "            if filename.startswith(prefix) and filename.endswith(\".csv\"):\n",
        "                file_path = os.path.join(directory_path, filename)\n",
        "                # Read the file and concatenate it to the corresponding prefix dataframe\n",
        "                df = pd.read_csv(file_path, index_col=0)\n",
        "                concatenated_data[prefix] = pd.concat([concatenated_data[prefix], df], axis=0)\n",
        "                print(f\"Loaded and concatenated {filename}\")\n",
        "\n",
        "    return concatenated_data\n",
        "\n",
        "\n",
        "# Example usage\n",
        "directory_path = \".../Project/data/25/segmented_df/\"\n",
        "prefixes = ['segmented_df_emg', 'segmented_df_imu', 'segmented_df_ips', 'segmented_df_mocap']\n",
        "\n",
        "# Call function to concatenate files\n",
        "concatenated_data = concatenate_files_in_directory(directory_path, prefixes)\n",
        "\n",
        "# Example of accessing the concatenated data for each prefix\n",
        "for i in range(1, 26):\n",
        "    # Call function to concatenate files\n",
        "    directory_path = f\".../Project/data/{i}/segmented_df/\"\n",
        "    concatenated_data = concatenate_files_in_directory(directory_path, prefixes)\n",
        "    for prefix, data in concatenated_data.items():\n",
        "        data.to_csv(f\".../Project/data/{i}/segmented_df/concatenated_data_{prefix}.csv\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zvRw4fcyy2wd",
        "outputId": "193a229a-8949-4636-fa5f-73f9655a71a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded and concatenated segmented_df_emg_1.csv\n",
            "Loaded and concatenated segmented_df_imu_1.csv\n",
            "Loaded and concatenated segmented_df_ips_1.csv\n",
            "Loaded and concatenated segmented_df_mocap_1.csv\n",
            "Loaded and concatenated segmented_df_emg_2.csv\n",
            "Loaded and concatenated segmented_df_emg_3.csv\n",
            "Loaded and concatenated segmented_df_imu_2.csv\n",
            "Loaded and concatenated segmented_df_imu_3.csv\n",
            "Loaded and concatenated segmented_df_ips_2.csv\n",
            "Loaded and concatenated segmented_df_ips_3.csv\n",
            "Loaded and concatenated segmented_df_mocap_3.csv\n",
            "Loaded and concatenated segmented_df_mocap_2.csv\n",
            "Loaded and concatenated segmented_df_emg_1.csv\n",
            "Loaded and concatenated segmented_df_imu_1.csv\n",
            "Loaded and concatenated segmented_df_ips_1.csv\n",
            "Loaded and concatenated segmented_df_mocap_1.csv\n",
            "Loaded and concatenated segmented_df_emg_1.csv\n",
            "Loaded and concatenated segmented_df_imu_1.csv\n",
            "Loaded and concatenated segmented_df_ips_1.csv\n",
            "Loaded and concatenated segmented_df_mocap_1.csv\n",
            "Loaded and concatenated segmented_df_emg_1.csv\n",
            "Loaded and concatenated segmented_df_imu_1.csv\n",
            "Loaded and concatenated segmented_df_ips_1.csv\n",
            "Loaded and concatenated segmented_df_mocap_1.csv\n",
            "Loaded and concatenated segmented_df_emg_2.csv\n",
            "Loaded and concatenated segmented_df_imu_2.csv\n",
            "Loaded and concatenated segmented_df_ips_2.csv\n",
            "Loaded and concatenated segmented_df_mocap_2.csv\n",
            "Loaded and concatenated segmented_df_emg_1.csv\n",
            "Loaded and concatenated segmented_df_imu_1.csv\n",
            "Loaded and concatenated segmented_df_ips_1.csv\n",
            "Loaded and concatenated segmented_df_mocap_1.csv\n",
            "Loaded and concatenated segmented_df_emg_1.csv\n",
            "Loaded and concatenated segmented_df_imu_1.csv\n",
            "Loaded and concatenated segmented_df_ips_1.csv\n",
            "Loaded and concatenated segmented_df_mocap_1.csv\n",
            "Loaded and concatenated segmented_df_emg_1.csv\n",
            "Loaded and concatenated segmented_df_imu_1.csv\n",
            "Loaded and concatenated segmented_df_ips_1.csv\n",
            "Loaded and concatenated segmented_df_mocap_1.csv\n",
            "Loaded and concatenated segmented_df_emg_1.csv\n",
            "Loaded and concatenated segmented_df_imu_1.csv\n",
            "Loaded and concatenated segmented_df_ips_1.csv\n",
            "Loaded and concatenated segmented_df_mocap_1.csv\n",
            "Loaded and concatenated segmented_df_emg_1.csv\n",
            "Loaded and concatenated segmented_df_imu_1.csv\n",
            "Loaded and concatenated segmented_df_ips_1.csv\n",
            "Loaded and concatenated segmented_df_mocap_1.csv\n",
            "Loaded and concatenated segmented_df_emg_2.csv\n",
            "Loaded and concatenated segmented_df_imu_2.csv\n",
            "Loaded and concatenated segmented_df_ips_2.csv\n",
            "Loaded and concatenated segmented_df_mocap_2.csv\n",
            "Loaded and concatenated segmented_df_emg_1.csv\n",
            "Loaded and concatenated segmented_df_imu_1.csv\n",
            "Loaded and concatenated segmented_df_ips_1.csv\n",
            "Loaded and concatenated segmented_df_mocap_1.csv\n",
            "Loaded and concatenated segmented_df_emg_1.csv\n",
            "Loaded and concatenated segmented_df_imu_1.csv\n",
            "Loaded and concatenated segmented_df_ips_1.csv\n",
            "Loaded and concatenated segmented_df_mocap_1.csv\n",
            "Loaded and concatenated segmented_df_emg_1.csv\n",
            "Loaded and concatenated segmented_df_imu_1.csv\n",
            "Loaded and concatenated segmented_df_ips_1.csv\n",
            "Loaded and concatenated segmented_df_mocap_1.csv\n",
            "Loaded and concatenated segmented_df_emg_1.csv\n",
            "Loaded and concatenated segmented_df_imu_1.csv\n",
            "Loaded and concatenated segmented_df_ips_1.csv\n",
            "Loaded and concatenated segmented_df_mocap_1.csv\n",
            "Loaded and concatenated segmented_df_emg_1.csv\n",
            "Loaded and concatenated segmented_df_imu_1.csv\n",
            "Loaded and concatenated segmented_df_ips_1.csv\n",
            "Loaded and concatenated segmented_df_mocap_1.csv\n",
            "Loaded and concatenated segmented_df_emg_1.csv\n",
            "Loaded and concatenated segmented_df_imu_1.csv\n",
            "Loaded and concatenated segmented_df_ips_1.csv\n",
            "Loaded and concatenated segmented_df_mocap_1.csv\n",
            "Loaded and concatenated segmented_df_emg_1.csv\n",
            "Loaded and concatenated segmented_df_imu_1.csv\n",
            "Loaded and concatenated segmented_df_ips_1.csv\n",
            "Loaded and concatenated segmented_df_mocap_1.csv\n",
            "Loaded and concatenated segmented_df_emg_2.csv\n",
            "Loaded and concatenated segmented_df_imu_2.csv\n",
            "Loaded and concatenated segmented_df_ips_2.csv\n",
            "Loaded and concatenated segmented_df_mocap_2.csv\n",
            "Loaded and concatenated segmented_df_emg_1.csv\n",
            "Loaded and concatenated segmented_df_imu_1.csv\n",
            "Loaded and concatenated segmented_df_ips_1.csv\n",
            "Loaded and concatenated segmented_df_mocap_1.csv\n",
            "Loaded and concatenated segmented_df_emg_1.csv\n",
            "Loaded and concatenated segmented_df_imu_1.csv\n",
            "Loaded and concatenated segmented_df_ips_1.csv\n",
            "Loaded and concatenated segmented_df_mocap_1.csv\n",
            "Loaded and concatenated segmented_df_emg_1.csv\n",
            "Loaded and concatenated segmented_df_imu_1.csv\n",
            "Loaded and concatenated segmented_df_ips_1.csv\n",
            "Loaded and concatenated segmented_df_mocap_1.csv\n",
            "Loaded and concatenated segmented_df_emg_1.csv\n",
            "Loaded and concatenated segmented_df_imu_1.csv\n",
            "Loaded and concatenated segmented_df_ips_1.csv\n",
            "Loaded and concatenated segmented_df_mocap_1.csv\n",
            "Loaded and concatenated segmented_df_emg_1.csv\n",
            "Loaded and concatenated segmented_df_imu_1.csv\n",
            "Loaded and concatenated segmented_df_ips_1.csv\n",
            "Loaded and concatenated segmented_df_mocap_1.csv\n",
            "Loaded and concatenated segmented_df_emg_2.csv\n",
            "Loaded and concatenated segmented_df_imu_2.csv\n",
            "Loaded and concatenated segmented_df_ips_2.csv\n",
            "Loaded and concatenated segmented_df_mocap_2.csv\n",
            "Loaded and concatenated segmented_df_emg_1.csv\n",
            "Loaded and concatenated segmented_df_imu_1.csv\n",
            "Loaded and concatenated segmented_df_ips_1.csv\n",
            "Loaded and concatenated segmented_df_mocap_1.csv\n",
            "Loaded and concatenated segmented_df_emg_1.csv\n",
            "Loaded and concatenated segmented_df_imu_1.csv\n",
            "Loaded and concatenated segmented_df_ips_1.csv\n",
            "Loaded and concatenated segmented_df_mocap_1.csv\n",
            "Loaded and concatenated segmented_df_emg_1.csv\n",
            "Loaded and concatenated segmented_df_imu_1.csv\n",
            "Loaded and concatenated segmented_df_ips_1.csv\n",
            "Loaded and concatenated segmented_df_mocap_1.csv\n",
            "Loaded and concatenated segmented_df_emg_1.csv\n",
            "Loaded and concatenated segmented_df_imu_1.csv\n",
            "Loaded and concatenated segmented_df_ips_1.csv\n",
            "Loaded and concatenated segmented_df_mocap_1.csv\n",
            "Loaded and concatenated segmented_df_emg_1.csv\n",
            "Loaded and concatenated segmented_df_imu_1.csv\n",
            "Loaded and concatenated segmented_df_ips_1.csv\n",
            "Loaded and concatenated segmented_df_mocap_1.csv\n",
            "Loaded and concatenated segmented_df_emg_2.csv\n",
            "Loaded and concatenated segmented_df_emg_3.csv\n",
            "Loaded and concatenated segmented_df_imu_2.csv\n",
            "Loaded and concatenated segmented_df_imu_3.csv\n",
            "Loaded and concatenated segmented_df_ips_2.csv\n",
            "Loaded and concatenated segmented_df_ips_3.csv\n",
            "Loaded and concatenated segmented_df_mocap_3.csv\n",
            "Loaded and concatenated segmented_df_mocap_2.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Concatenate EMG, IMU, IPS, and MoCap data for each person"
      ],
      "metadata": {
        "id": "GJsC3eieghFE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "# Base dataset path\n",
        "dataset_base_path = \".../Project/data\"\n",
        "\n",
        "# File names to concatenate\n",
        "file_names = [\n",
        "    \"concatenated_data_segmented_df_emg.csv\",\n",
        "    \"concatenated_data_segmented_df_imu.csv\",\n",
        "    \"concatenated_data_segmented_df_ips.csv\",\n",
        "    \"concatenated_data_segmented_df_mocap.csv\"\n",
        "]\n",
        "\n",
        "# Initialize dictionaries to store DataFrames for each file type\n",
        "concatenated_data = {file_name: [] for file_name in file_names}\n",
        "\n",
        "# Iterate through folders 1 to 25\n",
        "for folder_num in range(1, 26):\n",
        "    folder_path = os.path.join(dataset_base_path, str(folder_num), \"segmented_df\")\n",
        "\n",
        "    for file_name in file_names:\n",
        "        file_path = os.path.join(folder_path, file_name)\n",
        "        if os.path.exists(file_path):\n",
        "            # Read CSV and add a column for the folder number\n",
        "            df = pd.read_csv(file_path)\n",
        "            df[\"person_id\"] = folder_num  # Add a column for person ID\n",
        "            concatenated_data[file_name].append(df)\n",
        "        else:\n",
        "            print(f\"File not found: {file_path}\")\n",
        "\n",
        "# Concatenate all files of the same type and save\n",
        "output_path = \".../Project/concatenated_data\"\n",
        "os.makedirs(output_path, exist_ok=True)\n",
        "\n",
        "for file_name, dfs in concatenated_data.items():\n",
        "    if dfs:  # Only process if we have data\n",
        "        combined_df = pd.concat(dfs, ignore_index=True)\n",
        "        combined_file_path = os.path.join(output_path, file_name)\n",
        "        combined_df.to_csv(combined_file_path, index=False)\n",
        "        print(f\"Saved concatenated file: {combined_file_path}\")\n"
      ],
      "metadata": {
        "id": "sfdQPLXWgghd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**PS:** In the folder ../Project/concatenated_data, there are four CSV files: one for EMG, one for IMU, one for IPS, and one for MoCap. Each file contains information for all participants. As shown below, each CSV file includes two additional columns: one for **categories** and another for **patient IDs**."
      ],
      "metadata": {
        "id": "tB0orRIm__XO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_base_path = \".../Project/concatenated_data\"\n",
        "\n",
        "\n",
        "concatenated_data_segmented_df_emg = pd.read_csv(os.path.join(dataset_base_path, \"concatenated_data_segmented_df_emg.csv\"), index_col=0)\n",
        "concatenated_data_segmented_df_imu = pd.read_csv(os.path.join(dataset_base_path, \"concatenated_data_segmented_df_imu.csv\"), index_col=0)\n",
        "concatenated_data_segmented_df_ips = pd.read_csv(os.path.join(dataset_base_path, \"concatenated_data_segmented_df_ips.csv\"), index_col=0)\n",
        "concatenated_data_segmented_df_mocap = pd.read_csv(os.path.join(dataset_base_path, \"concatenated_data_segmented_df_mocap.csv\"), index_col=0)"
      ],
      "metadata": {
        "id": "fL3qhreZApnp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(concatenated_data_segmented_df_emg.shape)\n",
        "concatenated_data_segmented_df_emg.head(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 274
        },
        "id": "bCRvPwBYAv-r",
        "outputId": "1db70fd0-cd3c-4e82-db06-1e3f305cdec5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(113446, 66)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   R_Vlat_rms    R_RF_rms  R_ST_rms  R_TA_rms  L_Vlat_rms    L_RF_rms  \\\n",
              "0    3.154265  292.758180        65        38    3.696738  282.788085   \n",
              "1    3.677968  326.696778        69        37    4.208268  287.722779   \n",
              "2    3.800089  267.279053        50        26    3.798007  264.962768   \n",
              "3    3.374545  292.657471        61        39    4.385206  314.007569   \n",
              "4    4.138228  382.388306        64        34    3.381075  289.837644   \n",
              "\n",
              "   L_ST_rms  L_TA_rms  R_MG_rms    R_LG_rms  ...   R_MG_zc     R_LG_zc  \\\n",
              "0        56        34  3.684881  195.675659  ...  3.497438  229.110718   \n",
              "1        62        32  4.657688  368.994141  ...  9.854272  394.674683   \n",
              "2        44        20  3.792937  284.197999  ...  5.891582  253.179930   \n",
              "3        66        32  5.642971  368.893433  ...  7.399809  394.473266   \n",
              "4        61        32  5.003856  253.582763  ...  6.837258  340.795900   \n",
              "\n",
              "   R_SOL_zc  R_IL_zc   L_MG_zc     L_LG_zc  L_SOL_zc  L_IL_zc  category  \\\n",
              "0        51       27  3.413615  145.623779        29       21      back   \n",
              "1        51       23  5.228666  243.411255        48       24      back   \n",
              "2        35       12  4.752426  123.065186        34       12      back   \n",
              "3        40       24  2.422399  159.622193        38       24      back   \n",
              "4        52       32  4.945372  221.759034        34       22      back   \n",
              "\n",
              "   person_id  \n",
              "0          1  \n",
              "1          1  \n",
              "2          1  \n",
              "3          1  \n",
              "4          1  \n",
              "\n",
              "[5 rows x 66 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-198d7fe9-837e-49a8-af05-7dd812f0e643\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>R_Vlat_rms</th>\n",
              "      <th>R_RF_rms</th>\n",
              "      <th>R_ST_rms</th>\n",
              "      <th>R_TA_rms</th>\n",
              "      <th>L_Vlat_rms</th>\n",
              "      <th>L_RF_rms</th>\n",
              "      <th>L_ST_rms</th>\n",
              "      <th>L_TA_rms</th>\n",
              "      <th>R_MG_rms</th>\n",
              "      <th>R_LG_rms</th>\n",
              "      <th>...</th>\n",
              "      <th>R_MG_zc</th>\n",
              "      <th>R_LG_zc</th>\n",
              "      <th>R_SOL_zc</th>\n",
              "      <th>R_IL_zc</th>\n",
              "      <th>L_MG_zc</th>\n",
              "      <th>L_LG_zc</th>\n",
              "      <th>L_SOL_zc</th>\n",
              "      <th>L_IL_zc</th>\n",
              "      <th>category</th>\n",
              "      <th>person_id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3.154265</td>\n",
              "      <td>292.758180</td>\n",
              "      <td>65</td>\n",
              "      <td>38</td>\n",
              "      <td>3.696738</td>\n",
              "      <td>282.788085</td>\n",
              "      <td>56</td>\n",
              "      <td>34</td>\n",
              "      <td>3.684881</td>\n",
              "      <td>195.675659</td>\n",
              "      <td>...</td>\n",
              "      <td>3.497438</td>\n",
              "      <td>229.110718</td>\n",
              "      <td>51</td>\n",
              "      <td>27</td>\n",
              "      <td>3.413615</td>\n",
              "      <td>145.623779</td>\n",
              "      <td>29</td>\n",
              "      <td>21</td>\n",
              "      <td>back</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3.677968</td>\n",
              "      <td>326.696778</td>\n",
              "      <td>69</td>\n",
              "      <td>37</td>\n",
              "      <td>4.208268</td>\n",
              "      <td>287.722779</td>\n",
              "      <td>62</td>\n",
              "      <td>32</td>\n",
              "      <td>4.657688</td>\n",
              "      <td>368.994141</td>\n",
              "      <td>...</td>\n",
              "      <td>9.854272</td>\n",
              "      <td>394.674683</td>\n",
              "      <td>51</td>\n",
              "      <td>23</td>\n",
              "      <td>5.228666</td>\n",
              "      <td>243.411255</td>\n",
              "      <td>48</td>\n",
              "      <td>24</td>\n",
              "      <td>back</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3.800089</td>\n",
              "      <td>267.279053</td>\n",
              "      <td>50</td>\n",
              "      <td>26</td>\n",
              "      <td>3.798007</td>\n",
              "      <td>264.962768</td>\n",
              "      <td>44</td>\n",
              "      <td>20</td>\n",
              "      <td>3.792937</td>\n",
              "      <td>284.197999</td>\n",
              "      <td>...</td>\n",
              "      <td>5.891582</td>\n",
              "      <td>253.179930</td>\n",
              "      <td>35</td>\n",
              "      <td>12</td>\n",
              "      <td>4.752426</td>\n",
              "      <td>123.065186</td>\n",
              "      <td>34</td>\n",
              "      <td>12</td>\n",
              "      <td>back</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3.374545</td>\n",
              "      <td>292.657471</td>\n",
              "      <td>61</td>\n",
              "      <td>39</td>\n",
              "      <td>4.385206</td>\n",
              "      <td>314.007569</td>\n",
              "      <td>66</td>\n",
              "      <td>32</td>\n",
              "      <td>5.642971</td>\n",
              "      <td>368.893433</td>\n",
              "      <td>...</td>\n",
              "      <td>7.399809</td>\n",
              "      <td>394.473266</td>\n",
              "      <td>40</td>\n",
              "      <td>24</td>\n",
              "      <td>2.422399</td>\n",
              "      <td>159.622193</td>\n",
              "      <td>38</td>\n",
              "      <td>24</td>\n",
              "      <td>back</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4.138228</td>\n",
              "      <td>382.388306</td>\n",
              "      <td>64</td>\n",
              "      <td>34</td>\n",
              "      <td>3.381075</td>\n",
              "      <td>289.837644</td>\n",
              "      <td>61</td>\n",
              "      <td>32</td>\n",
              "      <td>5.003856</td>\n",
              "      <td>253.582763</td>\n",
              "      <td>...</td>\n",
              "      <td>6.837258</td>\n",
              "      <td>340.795900</td>\n",
              "      <td>52</td>\n",
              "      <td>32</td>\n",
              "      <td>4.945372</td>\n",
              "      <td>221.759034</td>\n",
              "      <td>34</td>\n",
              "      <td>22</td>\n",
              "      <td>back</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 66 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-198d7fe9-837e-49a8-af05-7dd812f0e643')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-198d7fe9-837e-49a8-af05-7dd812f0e643 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-198d7fe9-837e-49a8-af05-7dd812f0e643');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-cff608f3-e419-4a3a-9497-9c144194f41f\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-cff608f3-e419-4a3a-9497-9c144194f41f')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-cff608f3-e419-4a3a-9497-9c144194f41f button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "concatenated_data_segmented_df_emg"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(concatenated_data_segmented_df_imu.shape)\n",
        "concatenated_data_segmented_df_imu.head(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 274
        },
        "id": "pOlmX-8EAxg_",
        "outputId": "0bfa3f60-4817-48c5-c603-34dd4a093e20"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(113448, 56)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Head_Acc_X_mean  Head_Acc_Y_mean  Head_Acc_Z_mean  Head_Gyr_X_mean  \\\n",
              "0         8.904977         0.384233         4.042627        -0.011431   \n",
              "1         8.932194         0.351909         4.096076         0.003090   \n",
              "2         8.815747         0.335551         4.130934         0.012052   \n",
              "3         8.806464         0.340593         4.196511         0.011351   \n",
              "4         8.825958         0.329816         4.230514         0.006858   \n",
              "\n",
              "   Head_Gyr_Y_mean  Head_Gyr_Z_mean  Head_Roll_mean  Head_Pitch_mean  \\\n",
              "0         0.014266        -0.003312      -12.650186       -10.219978   \n",
              "1         0.032560         0.018453      -12.710571       -10.173904   \n",
              "2         0.044186         0.031625      -12.830830       -10.102711   \n",
              "3         0.028329         0.028800      -12.935340       -10.051806   \n",
              "4         0.029847         0.023784      -13.026545       -10.009585   \n",
              "\n",
              "   Head_Yaw_mean  Waist_Acc_X_mean  ...  R_F_Acc_Y_mean  R_F_Acc_Z_mean  \\\n",
              "0      30.065427          9.556038  ...       -1.945828        9.028294   \n",
              "1      30.079566          9.562018  ...       -1.917709        9.022139   \n",
              "2      30.164629          9.567548  ...       -1.950754        9.035559   \n",
              "3      30.253489          9.566574  ...       -1.918910        9.035628   \n",
              "4      30.324697          9.551094  ...       -1.935038        9.027972   \n",
              "\n",
              "   R_F_Gyr_X_mean  R_F_Gyr_Y_mean  R_F_Gyr_Z_mean  R_F_Roll_mean  \\\n",
              "0       -0.011208        0.003525       -0.006971      10.771145   \n",
              "1       -0.002480        0.000588        0.005154      10.758786   \n",
              "2        0.000660        0.002772        0.008308      10.741950   \n",
              "3        0.011773       -0.010301        0.003964      10.756064   \n",
              "4        0.000204        0.002880        0.009668      10.757534   \n",
              "\n",
              "   R_F_Pitch_mean  R_F_Yaw_mean  category  person_id  \n",
              "0       35.535060    -17.801271      back          1  \n",
              "1       35.533102    -17.822135      back          1  \n",
              "2       35.548250    -17.824800      back          1  \n",
              "3       35.528137    -17.802386      back          1  \n",
              "4       35.522094    -17.784689      back          1  \n",
              "\n",
              "[5 rows x 56 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b877d68c-712d-42ff-ae2f-9235b10a6600\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Head_Acc_X_mean</th>\n",
              "      <th>Head_Acc_Y_mean</th>\n",
              "      <th>Head_Acc_Z_mean</th>\n",
              "      <th>Head_Gyr_X_mean</th>\n",
              "      <th>Head_Gyr_Y_mean</th>\n",
              "      <th>Head_Gyr_Z_mean</th>\n",
              "      <th>Head_Roll_mean</th>\n",
              "      <th>Head_Pitch_mean</th>\n",
              "      <th>Head_Yaw_mean</th>\n",
              "      <th>Waist_Acc_X_mean</th>\n",
              "      <th>...</th>\n",
              "      <th>R_F_Acc_Y_mean</th>\n",
              "      <th>R_F_Acc_Z_mean</th>\n",
              "      <th>R_F_Gyr_X_mean</th>\n",
              "      <th>R_F_Gyr_Y_mean</th>\n",
              "      <th>R_F_Gyr_Z_mean</th>\n",
              "      <th>R_F_Roll_mean</th>\n",
              "      <th>R_F_Pitch_mean</th>\n",
              "      <th>R_F_Yaw_mean</th>\n",
              "      <th>category</th>\n",
              "      <th>person_id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>8.904977</td>\n",
              "      <td>0.384233</td>\n",
              "      <td>4.042627</td>\n",
              "      <td>-0.011431</td>\n",
              "      <td>0.014266</td>\n",
              "      <td>-0.003312</td>\n",
              "      <td>-12.650186</td>\n",
              "      <td>-10.219978</td>\n",
              "      <td>30.065427</td>\n",
              "      <td>9.556038</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.945828</td>\n",
              "      <td>9.028294</td>\n",
              "      <td>-0.011208</td>\n",
              "      <td>0.003525</td>\n",
              "      <td>-0.006971</td>\n",
              "      <td>10.771145</td>\n",
              "      <td>35.535060</td>\n",
              "      <td>-17.801271</td>\n",
              "      <td>back</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>8.932194</td>\n",
              "      <td>0.351909</td>\n",
              "      <td>4.096076</td>\n",
              "      <td>0.003090</td>\n",
              "      <td>0.032560</td>\n",
              "      <td>0.018453</td>\n",
              "      <td>-12.710571</td>\n",
              "      <td>-10.173904</td>\n",
              "      <td>30.079566</td>\n",
              "      <td>9.562018</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.917709</td>\n",
              "      <td>9.022139</td>\n",
              "      <td>-0.002480</td>\n",
              "      <td>0.000588</td>\n",
              "      <td>0.005154</td>\n",
              "      <td>10.758786</td>\n",
              "      <td>35.533102</td>\n",
              "      <td>-17.822135</td>\n",
              "      <td>back</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8.815747</td>\n",
              "      <td>0.335551</td>\n",
              "      <td>4.130934</td>\n",
              "      <td>0.012052</td>\n",
              "      <td>0.044186</td>\n",
              "      <td>0.031625</td>\n",
              "      <td>-12.830830</td>\n",
              "      <td>-10.102711</td>\n",
              "      <td>30.164629</td>\n",
              "      <td>9.567548</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.950754</td>\n",
              "      <td>9.035559</td>\n",
              "      <td>0.000660</td>\n",
              "      <td>0.002772</td>\n",
              "      <td>0.008308</td>\n",
              "      <td>10.741950</td>\n",
              "      <td>35.548250</td>\n",
              "      <td>-17.824800</td>\n",
              "      <td>back</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>8.806464</td>\n",
              "      <td>0.340593</td>\n",
              "      <td>4.196511</td>\n",
              "      <td>0.011351</td>\n",
              "      <td>0.028329</td>\n",
              "      <td>0.028800</td>\n",
              "      <td>-12.935340</td>\n",
              "      <td>-10.051806</td>\n",
              "      <td>30.253489</td>\n",
              "      <td>9.566574</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.918910</td>\n",
              "      <td>9.035628</td>\n",
              "      <td>0.011773</td>\n",
              "      <td>-0.010301</td>\n",
              "      <td>0.003964</td>\n",
              "      <td>10.756064</td>\n",
              "      <td>35.528137</td>\n",
              "      <td>-17.802386</td>\n",
              "      <td>back</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>8.825958</td>\n",
              "      <td>0.329816</td>\n",
              "      <td>4.230514</td>\n",
              "      <td>0.006858</td>\n",
              "      <td>0.029847</td>\n",
              "      <td>0.023784</td>\n",
              "      <td>-13.026545</td>\n",
              "      <td>-10.009585</td>\n",
              "      <td>30.324697</td>\n",
              "      <td>9.551094</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.935038</td>\n",
              "      <td>9.027972</td>\n",
              "      <td>0.000204</td>\n",
              "      <td>0.002880</td>\n",
              "      <td>0.009668</td>\n",
              "      <td>10.757534</td>\n",
              "      <td>35.522094</td>\n",
              "      <td>-17.784689</td>\n",
              "      <td>back</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 56 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b877d68c-712d-42ff-ae2f-9235b10a6600')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-b877d68c-712d-42ff-ae2f-9235b10a6600 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-b877d68c-712d-42ff-ae2f-9235b10a6600');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-c9f93962-5ff4-4c39-aa23-c353401f88b3\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c9f93962-5ff4-4c39-aa23-c353401f88b3')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-c9f93962-5ff4-4c39-aa23-c353401f88b3 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "concatenated_data_segmented_df_imu"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(concatenated_data_segmented_df_ips.shape)\n",
        "concatenated_data_segmented_df_ips.head(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 274
        },
        "id": "ts42bDUJAzLB",
        "outputId": "0ce6f614-f625-403c-a87e-67e6969758d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(117600, 684)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   0_mean  1_mean  2_mean  3_mean  4_mean  5_mean  6_mean    7_mean  8_mean  \\\n",
              "0     0.0     0.0     0.0     0.0     0.0     0.0     0.0  1.606667     0.0   \n",
              "1     0.0     0.0     0.0     0.0     0.0     0.0     0.0  1.460000     0.0   \n",
              "2     0.0     0.0     0.0     0.0     0.0     0.0     0.0  1.460000     0.0   \n",
              "3     0.0     0.0     0.0     0.0     0.0     0.0     0.0  1.680000     0.0   \n",
              "4     0.0     0.0     0.0     0.0     0.0     0.0     0.0  1.606667     0.0   \n",
              "\n",
              "   9_mean  ...  674_mean  675_mean  676_mean  677_mean  678_mean  679_mean  \\\n",
              "0     0.0  ...       0.0       0.0       0.0       0.0       0.0      1.12   \n",
              "1     0.0  ...       0.0       0.0       0.0       0.0       0.0      1.12   \n",
              "2     0.0  ...       0.0       0.0       0.0       0.0       0.0      1.12   \n",
              "3     0.0  ...       0.0       0.0       0.0       0.0       0.0      1.12   \n",
              "4     0.0  ...       0.0       0.0       0.0       0.0       0.0      1.12   \n",
              "\n",
              "   680_mean  681_mean  category  person_id  \n",
              "0       0.0       0.0      back          1  \n",
              "1       0.0       0.0      back          1  \n",
              "2       0.0       0.0      back          1  \n",
              "3       0.0       0.0      back          1  \n",
              "4       0.0       0.0      back          1  \n",
              "\n",
              "[5 rows x 684 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-593fec70-58c3-43c9-891a-2d1a1542d8d4\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0_mean</th>\n",
              "      <th>1_mean</th>\n",
              "      <th>2_mean</th>\n",
              "      <th>3_mean</th>\n",
              "      <th>4_mean</th>\n",
              "      <th>5_mean</th>\n",
              "      <th>6_mean</th>\n",
              "      <th>7_mean</th>\n",
              "      <th>8_mean</th>\n",
              "      <th>9_mean</th>\n",
              "      <th>...</th>\n",
              "      <th>674_mean</th>\n",
              "      <th>675_mean</th>\n",
              "      <th>676_mean</th>\n",
              "      <th>677_mean</th>\n",
              "      <th>678_mean</th>\n",
              "      <th>679_mean</th>\n",
              "      <th>680_mean</th>\n",
              "      <th>681_mean</th>\n",
              "      <th>category</th>\n",
              "      <th>person_id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.606667</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.12</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>back</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.460000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.12</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>back</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.460000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.12</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>back</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.680000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.12</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>back</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.606667</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.12</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>back</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 684 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-593fec70-58c3-43c9-891a-2d1a1542d8d4')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-593fec70-58c3-43c9-891a-2d1a1542d8d4 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-593fec70-58c3-43c9-891a-2d1a1542d8d4');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-d2b50812-d9b3-4e69-a638-28844ba79a0c\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d2b50812-d9b3-4e69-a638-28844ba79a0c')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-d2b50812-d9b3-4e69-a638-28844ba79a0c button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "concatenated_data_segmented_df_ips"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(concatenated_data_segmented_df_mocap.shape)\n",
        "concatenated_data_segmented_df_mocap.head(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 274
        },
        "id": "u1Du0vZ2A1Q5",
        "outputId": "16b5ad7e-fbbd-4c7d-ddff-8dde8dcbef58"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(113448, 155)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   C7_mean_x  C7_mean_y  C7_mean_z  RA_mean_x  RA_mean_y  RA_mean_z  \\\n",
              "0   0.182445   0.023007   1.402115   0.295875  -0.130377   1.394484   \n",
              "1   0.182231   0.023087   1.402198   0.296074  -0.130325   1.394413   \n",
              "2   0.182379   0.022964   1.402230   0.296210  -0.130333   1.394380   \n",
              "3   0.182557   0.022945   1.402290   0.296361  -0.130337   1.394363   \n",
              "4   0.182692   0.022905   1.402271   0.296523  -0.130310   1.394320   \n",
              "\n",
              "   LA_mean_x  LA_mean_y  LA_mean_z  T8_mean_x  ...  L_LM_velocity_y  \\\n",
              "0   0.270495   0.187968   1.399205   0.149561  ...        -0.000554   \n",
              "1   0.270739   0.188166   1.399469   0.149692  ...        -0.002312   \n",
              "2   0.270884   0.188148   1.399508   0.149777  ...        -0.000166   \n",
              "3   0.271069   0.188148   1.399518   0.149930  ...         0.000001   \n",
              "4   0.271170   0.188165   1.399493   0.150038  ...         0.000018   \n",
              "\n",
              "   L_LM_velocity_z  L_CAL_velocity_x  L_CAL_velocity_y  L_CAL_velocity_z  \\\n",
              "0        -0.000430         -0.000011      1.492492e-06         -0.000003   \n",
              "1        -0.001826         -0.000012     -8.534617e-07         -0.000002   \n",
              "2        -0.000142         -0.000003      1.329413e-05         -0.000004   \n",
              "3         0.000015          0.000002     -9.381637e-06         -0.000010   \n",
              "4         0.000024         -0.000003      7.311105e-06          0.000011   \n",
              "\n",
              "   L_MH1_velocity_x  L_MH1_velocity_y  L_MH1_velocity_z  category  person_id  \n",
              "0     -1.646624e-05     -5.342223e-06         -0.000009      back          1  \n",
              "1     -8.245567e-06      2.573600e-06         -0.000001      back          1  \n",
              "2     -1.418989e-06     -2.591971e-06          0.000001      back          1  \n",
              "3      2.837870e-07     -4.829473e-07         -0.000006      back          1  \n",
              "4     -5.972218e-06     -7.379168e-06         -0.000009      back          1  \n",
              "\n",
              "[5 rows x 155 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-68c12a68-fca9-404e-8c46-48947677d5a1\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>C7_mean_x</th>\n",
              "      <th>C7_mean_y</th>\n",
              "      <th>C7_mean_z</th>\n",
              "      <th>RA_mean_x</th>\n",
              "      <th>RA_mean_y</th>\n",
              "      <th>RA_mean_z</th>\n",
              "      <th>LA_mean_x</th>\n",
              "      <th>LA_mean_y</th>\n",
              "      <th>LA_mean_z</th>\n",
              "      <th>T8_mean_x</th>\n",
              "      <th>...</th>\n",
              "      <th>L_LM_velocity_y</th>\n",
              "      <th>L_LM_velocity_z</th>\n",
              "      <th>L_CAL_velocity_x</th>\n",
              "      <th>L_CAL_velocity_y</th>\n",
              "      <th>L_CAL_velocity_z</th>\n",
              "      <th>L_MH1_velocity_x</th>\n",
              "      <th>L_MH1_velocity_y</th>\n",
              "      <th>L_MH1_velocity_z</th>\n",
              "      <th>category</th>\n",
              "      <th>person_id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.182445</td>\n",
              "      <td>0.023007</td>\n",
              "      <td>1.402115</td>\n",
              "      <td>0.295875</td>\n",
              "      <td>-0.130377</td>\n",
              "      <td>1.394484</td>\n",
              "      <td>0.270495</td>\n",
              "      <td>0.187968</td>\n",
              "      <td>1.399205</td>\n",
              "      <td>0.149561</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.000554</td>\n",
              "      <td>-0.000430</td>\n",
              "      <td>-0.000011</td>\n",
              "      <td>1.492492e-06</td>\n",
              "      <td>-0.000003</td>\n",
              "      <td>-1.646624e-05</td>\n",
              "      <td>-5.342223e-06</td>\n",
              "      <td>-0.000009</td>\n",
              "      <td>back</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.182231</td>\n",
              "      <td>0.023087</td>\n",
              "      <td>1.402198</td>\n",
              "      <td>0.296074</td>\n",
              "      <td>-0.130325</td>\n",
              "      <td>1.394413</td>\n",
              "      <td>0.270739</td>\n",
              "      <td>0.188166</td>\n",
              "      <td>1.399469</td>\n",
              "      <td>0.149692</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.002312</td>\n",
              "      <td>-0.001826</td>\n",
              "      <td>-0.000012</td>\n",
              "      <td>-8.534617e-07</td>\n",
              "      <td>-0.000002</td>\n",
              "      <td>-8.245567e-06</td>\n",
              "      <td>2.573600e-06</td>\n",
              "      <td>-0.000001</td>\n",
              "      <td>back</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.182379</td>\n",
              "      <td>0.022964</td>\n",
              "      <td>1.402230</td>\n",
              "      <td>0.296210</td>\n",
              "      <td>-0.130333</td>\n",
              "      <td>1.394380</td>\n",
              "      <td>0.270884</td>\n",
              "      <td>0.188148</td>\n",
              "      <td>1.399508</td>\n",
              "      <td>0.149777</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.000166</td>\n",
              "      <td>-0.000142</td>\n",
              "      <td>-0.000003</td>\n",
              "      <td>1.329413e-05</td>\n",
              "      <td>-0.000004</td>\n",
              "      <td>-1.418989e-06</td>\n",
              "      <td>-2.591971e-06</td>\n",
              "      <td>0.000001</td>\n",
              "      <td>back</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.182557</td>\n",
              "      <td>0.022945</td>\n",
              "      <td>1.402290</td>\n",
              "      <td>0.296361</td>\n",
              "      <td>-0.130337</td>\n",
              "      <td>1.394363</td>\n",
              "      <td>0.271069</td>\n",
              "      <td>0.188148</td>\n",
              "      <td>1.399518</td>\n",
              "      <td>0.149930</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000001</td>\n",
              "      <td>0.000015</td>\n",
              "      <td>0.000002</td>\n",
              "      <td>-9.381637e-06</td>\n",
              "      <td>-0.000010</td>\n",
              "      <td>2.837870e-07</td>\n",
              "      <td>-4.829473e-07</td>\n",
              "      <td>-0.000006</td>\n",
              "      <td>back</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.182692</td>\n",
              "      <td>0.022905</td>\n",
              "      <td>1.402271</td>\n",
              "      <td>0.296523</td>\n",
              "      <td>-0.130310</td>\n",
              "      <td>1.394320</td>\n",
              "      <td>0.271170</td>\n",
              "      <td>0.188165</td>\n",
              "      <td>1.399493</td>\n",
              "      <td>0.150038</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000018</td>\n",
              "      <td>0.000024</td>\n",
              "      <td>-0.000003</td>\n",
              "      <td>7.311105e-06</td>\n",
              "      <td>0.000011</td>\n",
              "      <td>-5.972218e-06</td>\n",
              "      <td>-7.379168e-06</td>\n",
              "      <td>-0.000009</td>\n",
              "      <td>back</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 155 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-68c12a68-fca9-404e-8c46-48947677d5a1')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-68c12a68-fca9-404e-8c46-48947677d5a1 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-68c12a68-fca9-404e-8c46-48947677d5a1');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-b9820ab1-0c4b-4eaf-bba0-7606ee15fc50\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b9820ab1-0c4b-4eaf-bba0-7606ee15fc50')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-b9820ab1-0c4b-4eaf-bba0-7606ee15fc50 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "concatenated_data_segmented_df_mocap"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**As we can see, the data is not homogeneous; we have different shapes across each dataset, which could be problematic for the future training of our unified or multimodal model.**"
      ],
      "metadata": {
        "id": "zXshnWvNA4KP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Method 1"
      ],
      "metadata": {
        "id": "iepC0Xe5A6wC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Therefore, we will select data across emg, imu, ips, and mocap datasets that has the same shape and the same sequence of categories."
      ],
      "metadata": {
        "id": "EnhypFBQGkHl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def verify_and_filter_datasets(emg_df, imu_df, ips_df, mocap_df):\n",
        "    \"\"\"\n",
        "    Verifies if each person's data across emg, imu, ips, and mocap datasets\n",
        "    has the same shape and the same sequence of categories. Removes inconsistent persons.\n",
        "\n",
        "    Args:\n",
        "    - emg_df, imu_df, ips_df, mocap_df: DataFrames for emg, imu, ips, and mocap datasets.\n",
        "\n",
        "    Returns:\n",
        "    - Filtered DataFrames for emg, imu, ips, and mocap with only consistent persons.\n",
        "    \"\"\"\n",
        "    # List of datasets\n",
        "    datasets = [emg_df, imu_df, ips_df, mocap_df]\n",
        "    dataset_names = ['EMG', 'IMU', 'IPS', 'MOCAP']\n",
        "\n",
        "    # Extract unique person IDs from each dataset\n",
        "    person_ids = set(emg_df['person_id']).intersection(\n",
        "        imu_df['person_id'], ips_df['person_id'], mocap_df['person_id']\n",
        "    )\n",
        "\n",
        "    # Valid person IDs\n",
        "    valid_person_ids = []\n",
        "\n",
        "    for person_id in person_ids:\n",
        "        # Filter each dataset for the current person\n",
        "        person_data = {name: df[df['person_id'] == person_id] for name, df in zip(dataset_names, datasets)}\n",
        "\n",
        "        # Extract category sequences\n",
        "        category_sequences = {name: data['category'].reset_index(drop=True) for name, data in person_data.items()}\n",
        "\n",
        "        # Check if all category sequences are identical\n",
        "        first_dataset_name = dataset_names[0]\n",
        "        is_consistent = all(\n",
        "            seq.equals(category_sequences[first_dataset_name])\n",
        "            for seq in category_sequences.values()\n",
        "        )\n",
        "\n",
        "        # Check if all datasets have the same number of rows for the person\n",
        "        is_same_shape = all(\n",
        "            len(person_data[name]) == len(person_data[first_dataset_name])\n",
        "            for name in dataset_names\n",
        "        )\n",
        "\n",
        "        if is_consistent and is_same_shape:\n",
        "            valid_person_ids.append(person_id)\n",
        "\n",
        "    # Filter each dataset to include only valid persons\n",
        "    filtered_datasets = [df[df['person_id'].isin(valid_person_ids)] for df in datasets]\n",
        "\n",
        "    return tuple(filtered_datasets), valid_person_ids  # Return filtered datasets\n",
        "\n",
        "\n",
        "# Example usage:\n",
        "filtered_datasets, valid_person_ids = verify_and_filter_datasets(\n",
        "    concatenated_data_segmented_df_emg,\n",
        "    concatenated_data_segmented_df_imu,\n",
        "    concatenated_data_segmented_df_ips,\n",
        "    concatenated_data_segmented_df_mocap\n",
        ")\n",
        "\n",
        "# Display the results\n",
        "print(\"People kept :\", valid_person_ids)\n",
        "print(\"Filtered EMG shape:\", filtered_datasets[0].shape)\n",
        "print(\"Filtered IMU shape:\", filtered_datasets[1].shape)\n",
        "print(\"Filtered IPS shape:\", filtered_datasets[2].shape)\n",
        "print(\"Filtered MOCAP shape:\", filtered_datasets[3].shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0vI527uEA83k",
        "outputId": "8246f0af-ea61-4249-fe92-737be6ecad68"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "People kept : [1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 14, 15, 16, 17, 18, 19, 21, 22, 23, 24]\n",
            "Filtered EMG shape: (99364, 66)\n",
            "Filtered IMU shape: (99364, 56)\n",
            "Filtered IPS shape: (99364, 684)\n",
            "Filtered MOCAP shape: (99364, 155)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_base_path = \".../Project/dataset/method_1/\"\n",
        "filtered_datasets[0].to_csv(os.path.join(dataset_base_path, \"filtered_datasets_emg.csv\"))\n",
        "filtered_datasets[1].to_csv(os.path.join(dataset_base_path, \"filtered_datasets_imu.csv\"))\n",
        "filtered_datasets[2].to_csv(os.path.join(dataset_base_path, \"filtered_datasets_ips.csv\"))\n",
        "filtered_datasets[3].to_csv(os.path.join(dataset_base_path, \"filtered_datasets_mocap.csv\"))"
      ],
      "metadata": {
        "id": "-zj4ZWkoBq6b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "minimum_data_to_be_used = 113446\n",
        "new_used_data = 99364\n",
        "\n",
        "percentage_change = ((minimum_data_to_be_used-new_used_data) / minimum_data_to_be_used) * 100\n",
        "\n",
        "print(f\"The percentage of deleted data is: {percentage_change:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FqVQyQ-oA_ap",
        "outputId": "a70ca10f-ce3a-4140-dbe0-93d2019f26ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The percentage of deleted data is: 12.41%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Method 2"
      ],
      "metadata": {
        "id": "_YrS7yBPBBe8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Truncating Excess Data**\n",
        "\n",
        "If the IPS contains more data over a given period (e.g., due to differing recording durations or uneven sampling rates):\n",
        "\n",
        "  For example, if the EMG and IMU cover 10 seconds of recording, retain only the first 10 seconds of IPS data."
      ],
      "metadata": {
        "id": "neqklh-WBB5L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def align_person_data(emg_df, imu_df, ips_df, mocap_df):\n",
        "    \"\"\"\n",
        "    Align data for each person based on the minimum number of rows for that person\n",
        "    across all datasets (EMG, IMU, IPS, MOCAP).\n",
        "\n",
        "    Args:\n",
        "    - emg_df, imu_df, ips_df, mocap_df: DataFrames for EMG, IMU, IPS, and MOCAP datasets.\n",
        "\n",
        "    Returns:\n",
        "    - Aligned DataFrames for EMG, IMU, IPS, and MOCAP for each person.\n",
        "    \"\"\"\n",
        "    # List of datasets and dataset names\n",
        "    datasets = [emg_df, imu_df, ips_df, mocap_df]\n",
        "    dataset_names = ['EMG', 'IMU', 'IPS', 'MOCAP']\n",
        "\n",
        "    # Extract unique person IDs from each dataset\n",
        "    person_ids = set(emg_df['person_id']).intersection(\n",
        "        imu_df['person_id'], ips_df['person_id'], mocap_df['person_id']\n",
        "    )\n",
        "\n",
        "    # Create an empty list to store the aligned data for each dataset\n",
        "    aligned_datasets = []\n",
        "\n",
        "    for person_id in person_ids:\n",
        "        # Filter each dataset for the current person\n",
        "        person_data = {name: df[df['person_id'] == person_id] for name, df in zip(dataset_names, datasets)}\n",
        "\n",
        "        # Get the number of rows in each dataset for the current person\n",
        "        num_rows = {name: len(data) for name, data in person_data.items()}\n",
        "\n",
        "        # Find the minimum number of rows across the datasets for the current person\n",
        "        min_shape = min(num_rows.values())\n",
        "\n",
        "        # Extract categories to ensure alignment (use the category sequence from EMG, as an example)\n",
        "        valid_categories = person_data['EMG']['category']\n",
        "\n",
        "        # Align the datasets for the current person by taking the first `min_shape` rows\n",
        "        aligned_data_for_person = {}\n",
        "        for name, data in person_data.items():\n",
        "            # Filter the data by ensuring the category sequence is aligned and take the first `min_shape` rows\n",
        "            aligned_data_for_person[name] = data.head(min_shape)\n",
        "\n",
        "        # Append the aligned data for the current person\n",
        "        aligned_datasets.append({\n",
        "            name: aligned_data_for_person[name] for name in dataset_names\n",
        "        })\n",
        "\n",
        "    # Merge all aligned datasets (EMG, IMU, IPS, MOCAP) into a final list for each dataset\n",
        "    final_datasets = {name: pd.concat([aligned_data[name] for aligned_data in aligned_datasets]) for name in dataset_names}\n",
        "\n",
        "    return final_datasets['EMG'], final_datasets['IMU'], final_datasets['IPS'], final_datasets['MOCAP']\n",
        "\n",
        "\n",
        "# Example usage:\n",
        "aligned_emg, aligned_imu, aligned_ips, aligned_mocap = align_person_data(\n",
        "    concatenated_data_segmented_df_emg,\n",
        "    concatenated_data_segmented_df_imu,\n",
        "    concatenated_data_segmented_df_ips,\n",
        "    concatenated_data_segmented_df_mocap\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "# Display the results\n",
        "print(\"Aligned EMG shape:\", aligned_emg.shape)\n",
        "print(\"Aligned IMU shape:\", aligned_imu.shape)\n",
        "print(\"Aligned IPS shape:\", aligned_ips.shape)\n",
        "print(\"Aligned MOCAP shape:\", aligned_mocap.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pYAuLadiBGMc",
        "outputId": "6bc36e17-eb50-48e8-f4c1-908c41696c5b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Aligned EMG shape: (113446, 66)\n",
            "Aligned IMU shape: (113446, 56)\n",
            "Aligned IPS shape: (113446, 684)\n",
            "Aligned MOCAP shape: (113446, 155)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_base_path = \".../Project/dataset/method_2/\" # use the fulle path if you want to run it\n",
        "aligned_emg.to_csv(os.path.join(dataset_base_path, \"aligned_datasets_emg.csv\"))\n",
        "aligned_imu.to_csv(os.path.join(dataset_base_path, \"aligned_datasets_imu.csv\"))\n",
        "aligned_ips.to_csv(os.path.join(dataset_base_path, \"aligned_datasets_ips.csv\"))\n",
        "aligned_mocap.to_csv(os.path.join(dataset_base_path, \"aligned_datasets_mocap.csv\"))\n",
        "\n"
      ],
      "metadata": {
        "id": "4-_z6IyaBk8a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**PS** : If you're willing to run the notebook you'll need to replace ataset_base_path = \".../Project/dataset/method_2/\" by the full path"
      ],
      "metadata": {
        "id": "Eo7FjvSADtNe"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}